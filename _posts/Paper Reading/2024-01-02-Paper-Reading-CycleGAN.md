---
layout: post
title: "[Generative Model] CycleGAN : Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks"
author: kjy
date: 2024-01-02 15:17:00 +09:00
categories: [Deep Learning, Paper Reading]
tags: [Deep Learning, Paper Reading, Computer Vision, Generative Model]
comments: true
toc: true
math: true
---

í•´ë‹¹ í¬ìŠ¤íŠ¸ì—ì„œëŠ” [CycleGAN : Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networks](https://arxiv.org/abs/1703.10593) ë…¼ë¬¸ì„ í•¨ê»˜ ì½ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¬¸ì¥ë§ˆë‹¤ í•´ì„ì„ í•˜ê¸° ë³´ë‹¤ëŠ” ê° ë¬¸ë‹¨ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ìš”ì•½í•˜ëŠ” ì‹ìœ¼ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.

## Abstract

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_1.jpg){: width="400" .left}

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì˜ ì €ìë“¤ì€ paired examplesì´ ì—†ì„ ë•Œ image-to-image í•™ìŠµ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì—ì„œì˜ ëª©í‘œëŠ” mapping $G : X \rightarrow Y$ë¥¼ adversarial lossë¡œ í•™ìŠµí•˜ëŠ” ê²ƒì´ì§€ë§Œ ë§¤ìš° ì œì•½ì´ ë¶€ì¡±í•˜ê¸° ë•Œë¬¸ì— cycle consistency lossë¥¼ ì¶”ê°€í•´ $F(G(X)) \approx X$ë¥¼ í•™ìŠµí•¨ìœ¼ë¡œì¨ ëª©í‘œë¥¼ ì´ë£¹ë‹ˆë‹¤.

ğŸ” ì´ëŸ¬í•œ ì ‘ê·¼ë²•ì€ ì´ì „ ë°©ë²•ë“¤ê³¼ ë¹„êµí–ˆì„ ë•Œ ìš°ìˆ˜í•œ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 1. Introduction

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_2.jpg){: width="400" .left}

ğŸ” ìš°ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì´ ë‹¤ë¥¸ ë‘ ê·¸ë¦¼ ë˜ëŠ” ì‚¬ì§„ì˜ ìŠ¤íƒ€ì¼ì´ ë°”ë€ ê²°ê³¼ë¥¼ ë³¸ ì ì€ ì—†ì§€ë§Œ ìƒìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” ì´ëŸ¬í•œ ê²°ê³¼ë¥¼ ë§Œë“œëŠ” ë°©ë²•ì— ëŒ€í•´ ì œì‹œí•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_3.jpg){: width="400" .left}

ğŸ” ì´ì „ì˜ ì—°êµ¬ë“¤ì€ powerful translation system in supervised setting ì…ë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ paired training dataë¥¼ ì–»ê¸°ëŠ” ì‰½ì§€ ì•ŠìŠµë‹ˆë‹¤. íŠ¹íˆ style translationì—ì„œëŠ” ë”ìš± ì–´ë µìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_4.jpg){: width="400" .left}

ğŸ” ê·¸ë˜ì„œ í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” paired training data ì—†ì´ translation í•˜ëŠ” ì•Œê³ ë¦¬ì¦˜ì„ ì†Œê°œí•©ë‹ˆë‹¤.

ğŸ” ì—¬ê¸°ì„œ ì¤‘ìš”í•œ ê²ƒì€ domain ì‚¬ì´ì˜ ê·¼ë³¸ì ì¸ ê´€ê³„ê°€ ìˆê³  ì•Œê³ ë¦¬ì¦˜ì€ ê·¸ ê´€ê³„ë¥¼ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ ê¸°ì¡´ì˜ adversarial lossë§Œ ì‚¬ìš©í•  ê²½ìš° unpaired training dataë¥¼ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ê°™ì€ output $\hat{y}$ì„ mapping í•˜ëŠ” $G$ëŠ” ë¬´í•œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ë˜í•œ mode collapse í˜„ìƒì´ ë”ìš± ì˜ ë°œìƒí•˜ëŠ” ê²ƒì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_5.jpg){: width="400" .left}

ğŸ” ê·¸ë˜ì„œ ì €ìë“¤ì€ objective functionì— ë¬´ì—‡ì¸ê°€ ì¶”ê°€ë¥¼ í•´ì•¼ë§Œ í–ˆì—ˆê³  translationì˜ cycle consistent ì†ì„±ì„ ì´ìš©í–ˆìŠµë‹ˆë‹¤.

ğŸ” ì €ìë“¤ì€ ì´ëŸ¬í•œ ì†ì„±ì„ $F(G(x)) \approx x$ì™€ $G(F(y)) \approx y$ë¥¼ ê°•ìš”í•˜ëŠ” cycle consisitency lossë¥¼ objective functionì— ì¶”ê°€í•˜ì—¬ $G$ì™€ $F$ë¥¼ ë™ì‹œì— í•™ìŠµì‹œí‚´ìœ¼ë¡œì¨ ì´ìš©í•˜ê³ ì í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_6.jpg){: width="400" .left}

ğŸ” ì´ëŸ¬í•œ ë°©ë²•ì€ ë§ì€ ë¶„ì•¼ì— í­ë„“ê²Œ ì‚¬ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

ğŸ” ë˜í•œ hand-defined factorizations of style and contentê³¼ shared embedding functionsì— ê¸°ë°˜í•œ ì´ì „ ì—°êµ¬ë“¤ë³´ë‹¤ ì›”ë“±íˆ ë›°ì–´ë‚¨ì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 2. Related work

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_7.jpg){: width="400" .left}

ğŸ” `GANs` : ì €ìë“¤ì€ GANsë¥¼ ë§Œë“¤ì–´ì§„ ì´ë¯¸ì§€ë¥¼ êµ¬ë³„ ëª»í•˜ë„ë¡ translationí•˜ëŠ” mappingì„ í•™ìŠµí•˜ê¸°ìœ„í•´ adversarial lossë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

ğŸ” `Image-to-image translation` : ì´ì „ ì—°êµ¬ë“¤ê³¼ ë‹¬ë¦¬ paired-training data ì—†ì´ mappingì„ í•™ìŠµí•©ë‹ˆë‹¤.

ğŸ” `Unpaired image-to-image translation` : Bayesian framework, CoGAN, VAE + GANs, contentë¥¼ ê³µìœ í•˜ë„ë¡ í•˜ëŠ” ëª¨ë¸ì´ ìˆì§€ë§Œ CycleGANì€ general-purpose solutionì„ ëª¨ë¸ì…ë‹ˆë‹¤.

ğŸ” `Cycle Consistency` : ì–¸ì–´ ë„ë©”ì¸ì—ì„œë„ ìì£¼ ì‚¬ìš©í•˜ëŠ” ë°©ë²•, supervise CNN trainingì— cycle consistency lossë¥¼ ì‚¬ìš©í•œ ì´ì „ ì—°êµ¬, ë¹„ìŠ·í•œ ì—°êµ¬ì¸ DualGANì´ ìˆìŠµë‹ˆë‹¤.

ğŸ” `Neural Style Transfer` : Gram matrixì— ê¸°ë°˜í•œ ëª¨ë¸ì´ ì¡´ì¬í•˜ì§€ë§Œ ì´ëŸ¬í•œ ëª¨ë¸ì€ featureë¥¼ ë½‘ì•„ contentì™€ ê²°í•©í•˜ëŠ” ë°©ì‹ì´ë¯€ë¡œ ë‹¤ë¥¸ taskì— ì ìš©í•˜ê¸° í˜ë“­ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ CycleGANì€ mappingì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ taskì— ì ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 3. Formulation

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_8.jpg){: width="400" .left}

ğŸ” í•´ë‹¹ ì—°êµ¬ì˜ ëª©í‘œëŠ” ë‘ ê°œì˜ domain $X$ì™€ $Y$ ì‚¬ì´ì˜ mapping function($G$, $F$)ì„ í•™ìŠµí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ” í•´ë‹¹ ëª¨ë¸ì˜ objective functionì€ ë‘ ê°€ì§€ termì„ í¬í•¨í•©ë‹ˆë‹¤. (Adversarial loss + cycle consistency loss)

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 3.1 Adversarial Loss

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_9.jpg){: width="400" .left}

ğŸ” Mapping function $G : X \rightarrow Y$ì™€ $D_Y$ë¥¼ í•™ìŠµí•˜ëŠ” objective functionì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$\begin{align} \mathcal{L}_{GAN}(G, D_Y, X, Y) = &\mathbb{E}_{y \sim p_{data(y)}}[\log D_Y(y)]\ + \\ &\mathbb{E}_{x \sim p_{data(x)}}[\log (1 - D_Y(G(x)))] \end{align}$$

ğŸ” ë¹„ìŠ·í•˜ê²Œ $F : Y \rightarrow X$ë¥¼ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆê³  $G$ì™€ $F$ë¥¼ ìµœì í™” ì‹œí‚¤ê¸°ìœ„í•œ ì‹ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$\text{min}_G\text{max}_{D_Y}\ \mathcal{L}_{GAN}(G, D_Y, X, Y)$$

$$\text{min}_F\text{max}_{D_X}\ \mathcal{L}_{GAN}(F, D_X, Y, X)$$

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 3.2 Cycle Consistency Loss

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_10.jpg){: width="400" .left}

ğŸ” Cycle consistency lossë¥¼ ì¶”ê°€í•˜ëŠ” ì´ìœ  : Adversarial lossë§Œ ì‚¬ìš©í•  ê²½ìš° $x_i$ë¥¼ ëŒ€ì‘í•˜ëŠ” $y_i$ë¡œ ë…ë¦½ì ìœ¼ë¡œ mappingí•œë‹¤ê³  ë³´ì¥í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸

ğŸ” Forward cycle consistency :

$$x \rightarrow G(x) \rightarrow F(G(x)) \approx x$$

ğŸ” Backward cycle consistency :

$$y \rightarrow F(y) \rightarrow G(F(y)) \approx y$$

ğŸ” Cycle consistency loss :

$$\begin{align} \mathcal{L}_{cyc}(G, F) = & \mathbb{E}_{x \sim p_{data}(x)}[||F(G(x)) - x||_1]\ + \\ & \mathbb{E}_{y \sim p_{data}(y)}[||G(F(y)) - y||_1]\end{align}$$

ğŸ” L1 normì„ $F(G(x))$ì™€ $G(F(y))$ì˜ adversarial lossë¡œ ëŒ€ì²´í–ˆì„ ë•Œ ì¢‹ì§€ ì•Šì€ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 3.3 Full Objective

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_11.jpg){: width="400" .left}

ğŸ” ìµœì¢…ì ìœ¼ë¡œ CycleGANì˜ objective functionê³¼ ëª©í‘œëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$\begin{align} \mathcal{L}(G, F, D_X, D_Y) = &\mathcal{L}_{GAN}(G, D_Y, X, Y)\ + \\ &\mathcal{L}_{GAN}(F, D_X, Y, X)\ + \\ &\lambda\mathcal{L}_{cyc}(G, F) \end{align}$$

$$G^{*}, F^{*} = \text{arg}\ \underset{G, F}{\text{min}}\ \underset{D_x, D_y}{\text{max}}\ \mathcal{L}(G, F, D_X, D_Y)$$

ğŸ” CycleGANì„ ë‘ ê°œì˜ íŠ¹ë³„í•œ autoencoderë¥¼ í•™ìŠµí•œë‹¤ê³  ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” $F \circ G : X \rightarrow X$

ğŸ” $G \circ F : Y \rightarrow Y$

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 4. Implementation

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_12.jpg){: width="400" .left}

ğŸ” Model trainingì„ ì•ˆì •í™” ì‹œí‚¤ê¸°ìœ„í•´ ë‘ ê°€ì§€ techniqueì„ ì ìš©í•©ë‹ˆë‹¤.

ğŸ” ì²« ë²ˆì§¸, NLLì„ least-squares lossë¡œ ë³€ê²½í•©ë‹ˆë‹¤.

ğŸ” $\mathcal{L}_{GAN}(G, D, X, Y)$ëŠ” ì•„ë˜ì™€ ê°™ì´ ë³€ê²½ë©ë‹ˆë‹¤.

$$G^{*} = \underset{G}{\text{min}}\ \mathbb{E}_{x\sim p_{data}(x)}[(D(G(x)) - 1)^2]$$

$$\begin{align} D^{*} = \underset{G}{\text{min}}\ &\mathbb{E}_{y\sim p_{data}(y)}[(D(y) - 1)^2]\ + \\ &\mathbb{E}_{x\sim p_{data}(x)}[D(G(x))^2]\end{align}$$

ğŸ” ë‘ ë²ˆì§¸, ëª¨ë¸ì˜ osillationì„ ì¤„ì´ê¸° ìœ„í•´ SimGANì˜ ì „ëµì¸ ì´ì „ì— ë§Œë“¤ì–´ì§„ ì´ë¯¸ì§€ ì¤‘ ëœë¤í•˜ê²Œ ë½‘ì•„ discriminatorë¥¼ updateí•˜ëŠ” ë°©ë²•ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 5. Results

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_13.jpg){: width="400" .left}

ğŸ” ì²« ë²ˆì§¸, ìµœê·¼ ì—°êµ¬ë“¤ê³¼ CycleGANì„ ë¹„êµí•©ë‹ˆë‹¤.

ğŸ” ë‘ ë²ˆì§¸, Ablations of the full objectiveë¥¼ í†µí•´ ê° termì˜ ì¤‘ìš”ì„±ì„ íŒŒì•…í•©ë‹ˆë‹¤.

ğŸ” ì„¸ ë²ˆì§¸, paired training dataê°€ ì—†ì„ ë•Œ ë„“ê²Œ ì ìš©ë  ìˆ˜ ìˆëŠ” applicationì„ì„ í™•ì¸í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 5.1 Evaluation

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_14.jpg){: width="400" .left}

ğŸ” Pix2Pixì—ì„œ ì‚¬ìš©í•œ evaluation datasetsì™€ metricsë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

#### 5.1.1 Evaluation Metrics

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_15.jpg){: width="400" .left}

ğŸ” `AMT perceptual studies`

ğŸ” `FCN score`ë¥¼ í†µí•´ ìˆ˜ì¹˜ì ìœ¼ë¡œ ì´ë¯¸ì§€ì˜ í’ˆì§ˆì´ ì¢‹ì€ì§€ í™•ì¸

![](../../assets/img/Paper_Reading/blank.png){: .normal}

#### 5.1.2 Baselines

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_16.jpg){: width="400" .left}

ğŸ” `CoGAN` : Domain $X$ë¥¼ í•™ìŠµí•˜ëŠ” generatorì™€ domain $Y$ë¥¼ í•™ìŠµí•˜ëŠ” generatorëŠ” latent representationì„ ìœ„í•œ ì²˜ìŒ ëª‡ ê°œì˜ layerê°€ ì—°ê²°ëœ ìƒíƒœë¡œ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.

ğŸ” $X$ì—ì„œ $Y$ë¡œ translationì„ í•  ë•Œ $X$ë¥¼ ìƒì„±í•˜ëŠ” latent representationì„ ì°¾ì€ ë‹¤ìŒ ì°¾ì€ latent representationì„ style $Y$ë¡œ rendering í•˜ë©´ ë©ë‹ˆë‹¤.

ğŸ” `SimGAN` : CycleGANì²˜ëŸ¼ $X \rightarrow Y$ë¥¼ í•™ìŠµí•˜ê¸°ìœ„í•´ adeversarial lossë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

ğŸ” ì¶”ê°€ì ìœ¼ë¡œ pixel levelì—ì„œì˜ regularization termì„ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.

ğŸ” `Perceptual loss` : Deep feature spaceì—ì„œì˜ ê±°ë¦¬ë¥¼ ë¹„êµ

ğŸ” `BiGAN / ALI` : Image-to-imageê°€ ì•„ë‹Œ latent vector-to-imageë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.

ğŸ” `Pix2Pix` : CycleGANê³¼ ë‹¬ë¦¬ paired dataë¥¼ í•™ìŠµ dataë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

#### 5.1.3 Comparison against baselines

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_17.jpg){: width="400" .left}

ğŸ” ëª¨ë“  baselineì—ì„œ ë§Œì¡±í• ë§Œí•œ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í–ˆì§€ë§Œ CycleGANì€ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆìœ¼ë©° ì¢…ì¢… supervised pix2pixì™€ ê²¬ì¤„ë§Œí•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

ğŸ” `AMT` : Baselineë³´ë‹¤ ë§ì€ ì‚¬ëŒë“¤ì„ ì†ì˜€ìŠµë‹ˆë‹¤.

ğŸ” `FCN-scores` : Pix2Pixë¥¼ ë„˜ê¸°ëŠ” ì‰½ì§€ ì•Šì•˜ì§€ë§Œ ë‚˜ë¨¸ì§€ baselineì— ëŒ€í•´ì„œëŠ” ë§¤ìš° ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

#### 5.1.4 Analysis of the loss function

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_18.jpg){: width="400" .left}

ğŸ” Cycle consistency lossë§Œ ì‚¬ìš©í–ˆì„ ë•Œ ê·¸ë¦¬ê³  adversarial lossë§Œ ì‚¬ìš©í–ˆì„ ë•Œ ë§¤ìš° ì•ˆì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆê¸° ë•Œë¬¸ì— ë‘ termì€ CycleGANì—ì„œ ë§¤ìš° ì¤‘ìš”í•œ termì¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” One cycle consistency lossë¥¼ ì‚¬ìš©í•´ ì‹¤í—˜í–ˆì„ ë•Œ í•™ìŠµ ë¶ˆì•ˆì •ì„±ìœ¼ë¡œ ì¸í•´ mode collapse í˜„ìƒì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

#### 5.1.5 Image reconstruction quality

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_19.jpg){: width="400" .left}

ğŸ” Reconstructed imageê°€ ì¢…ì¢… original image $x$ì™€ ë¹„ìŠ·í•œ ê²ƒì„ ë°œê²¬í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

ğŸ¤” ëŒ€ë¶€ë¶„ì˜ reconstructed imageëŠ” original imageì™€ ë‹¤ë¥¼ ê²ƒìœ¼ë¡œ ì˜ˆìƒí•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 5.2 Applications

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_20.jpg){: width="400" .left}

ğŸ” `Collection style transfer` : ì„œë¡œ ë‹¤ë¥¸ í™”ê°€ì˜ ì‘í’ˆ

ğŸ” `Object transfiguration` : ë§ê³¼ ì–¼ë£©ë§

ğŸ” `Season transfer` : ì—¬ë¦„ê³¼ ê²¨ìš¸

ğŸ” `Photo generation from paintings` : ì‚¬ì§„ê³¼ í™”ê°€ì˜ ì‘í’ˆ

ğŸ” CycleGANì€ collectionì„ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— ë‚®ì¸ ì´ë¯¸ì§€ë¥¼ ë„£ì–´ë„ ì¼ëª°ì˜ ì´ë¯¸ì§€ê°€ ê²°ê³¼ë¡œ ë‚˜ì˜¬ ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ, í•´ë‹¹ taskì˜ ê²½ìš° ê°™ì€ ìƒ‰ê°ì„ ìœ ì§€í•´ì•¼ í•˜ë¯€ë¡œ $\mathcal{L}_{identity}(G, F)$ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.

$$\begin{align} \mathcal{L}_{identity}(G, F) = &\mathbb{E}_{y \sim p_{data}(y)}[||G(y) - y||_1]\ + \\ &\mathbb{E}_{x \sim p_{data}(x)}[||F(x) - x||_1] \end{align}$$

ğŸ” `Photo enhancement` : ë¬¼ì²´ ê°•ì¡°

ğŸ” `Comparison with Gatys et al.` : Neural style transferì™€ ë¹„êµ

ğŸ” Neural style transferëŠ” ì¢…ì¢… ì‹¤íŒ¨í•œ ê²°ê³¼ë¬¼ì„ ë§Œë“¤ì§€ë§Œ CycleGANì€ target domainê³¼ ìœ ì‚¬í•œ ê²°ê³¼ë¬¼ì„ ë§Œë“­ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 6. Limitations and Discussion

![](../../assets/img/Paper_Reading/CycleGAN/cyclegan_21.jpg){: width="400" .left}

ğŸ” ì„¤ë“ë ¥ ìˆëŠ” ê²°ê³¼ë¥¼ ì–»ê¸°ëŠ” í–ˆì§€ë§Œ ì—¬ì „íˆ ë¶€ì¡±í•œ ë¶€ë¶„ì´ ìˆìŠµë‹ˆë‹¤.

ğŸ” `Geometric` : ê°œì™€ ê³ ì–‘ì´ ê°™ì´ ê¸°í•˜í•™ì ìœ¼ë¡œ ë‹¤ë¥¸ í˜•íƒœë¥¼ ë„ëŠ” objectë¥¼ translation í•  ë•Œ ì¢‹ì§€ ì•Šì€ ê²°ê³¼ë¥¼ ë³´ì´ëŠ”ë° ì´ê²ƒì€ ì™¸ê´€ì„ ë³€ê²½í•˜ëŠ”ë° ì¢‹ì€ ì„±ëŠ¥ì„ ë³´ì¸ generator architectureë¥¼ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” `Ditribution of training data` : ë§ê³¼ ì–¼ë£©ë§ì— ëŒ€í•´ì„œ í•™ìŠµí•œ ê²½ìš° test imageë¡œ ë§ì„ íƒ€ê³  ìˆëŠ” ì‚¬ëŒì˜ ì´ë¯¸ì§€ë¥¼ ë³´ì—¬ì£¼ë©´ ì‚¬ëŒê¹Œì§€ ì–¼ë£©ë§ë¡œ ë°”ê¿”ë²„ë¦¬ëŠ” ê²°ê³¼ë¥¼ ì´ˆë˜í•©ë‹ˆë‹¤. ì™œëƒí•˜ë©´ training dataì—ëŠ” ê·¸ëŸ¬í•œ ì´ë¯¸ì§€ê°€ ì¡´ì¬í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

ğŸ” `Supervised VS Unsupervised` : ì—¬ì „í•œ gapì´ ì¡´ì¬í•˜ì§€ë§Œ semi-supervised dataë¥¼ ì‚¬ìš©í•œë‹¤ë©´ supervisedë³´ë‹¤ ì ì€ ë¹„ìš©ìœ¼ë¡œ ë¹„ìŠ·í•œ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}
