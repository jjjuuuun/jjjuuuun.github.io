---
layout: post
title: "[Generative Model] DDIM : Denoising Diffusion Implicit Models"
author: kjy
date: 2024-01-31 13:00:00 +09:00
categories: [Deep Learning, Paper Reading]
tags: [Deep Learning, Paper Reading, Computer Vision, Generative Model]
comments: true
toc: true
math: true
---

í•´ë‹¹ í¬ìŠ¤íŠ¸ì—ì„œëŠ” [DDPM : Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502) ë…¼ë¬¸ì„ í•¨ê»˜ ì½ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¬¸ì¥ë§ˆë‹¤ í•´ì„ì„ í•˜ê¸° ë³´ë‹¤ëŠ” ê° ë¬¸ë‹¨ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ìš”ì•½í•˜ëŠ” ì‹ìœ¼ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.

Emojiì˜ ì˜ë¯¸ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

ğŸ” : ë…¼ë¬¸ì— ìˆëŠ” ë‚´ìš©

ğŸ’¡ : ë…¼ë¬¸ì— ì í˜€ìˆì§€ ì•Šì€ ì‚¬ì „ì§€ì‹

ğŸ’­ : ì €ì˜ ìƒê°

â­ : ì¤‘ìš”í•œ ë‚´ìš©

âœ… : ë‚˜ì¤‘ì— í™•ì¸ì´ í•„ìš”í•œ ë‚´ìš©

## Abstract

![](../../assets/img/Paper_Reading/DDIM/ddim_1.jpg){: .normal}

ğŸ” DDPMì˜ ë‹¨ì  : Sampleì„ ìƒì„±í•˜ê¸°ìœ„í•´ ë§ì€ stepì˜ Markov chain ê³¼ì •ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.

ğŸ” DDIM : DDPMê³¼ ê°™ì€ objective functionì„ ë§Œë“œëŠ” non-Markovian diffusion processë¥¼ í†µí•´ í•™ìŠµ

> ğŸ” 10 ~ 50ë°° ì •ë„ DDPMë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤.  
> ğŸ” Semantically meaningful imageë¥¼ latent spaceì—ì„œ ë°”ë¡œ interpolationì„ í†µí•´ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
> ğŸ” ë§¤ìš° ë‚®ì€ reconstruction errorë¥¼ ê´€ì°°í–ˆìŠµë‹ˆë‹¤.

## 1. Introduction

![](../../assets/img/Paper_Reading/DDIM/ddim_2.jpg){: .normal}

ğŸ” Generative model : GANs, VAE, Autoregressive models, normalizaing flows

ğŸ” ê·¸ ì¤‘ GANsì´ ê°€ì¥ ì¢‹ì€ í’ˆì§ˆì„ ë§Œë“¤ì–´ëƒˆì§€ë§Œ í•™ìŠµ ì•ˆì •í™”ë¥¼ í•˜ê¸° ìœ„í•´ ë§¤ìš° ì‹ ì¤‘í•œ optimizationê³¼ architecture ì„ íƒì´ í•„ìš”í•©ë‹ˆë‹¤.

ğŸ” ìµœê·¼ì—ëŠ” iterative generative modelsì— ëŒ€í•œ ì—°êµ¬ê°€ ì§„í–‰(DDPM, NCSN)

ğŸ” Iterative generative modelì€ GANsê³¼ ê²¬ì¤„ë§Œí•œ í’ˆì§ˆì„ ìƒì„±í–ˆìœ¼ë©° GANsì— ë¹„í•´ í•™ìŠµì´ ì‰½ë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ ë†’ì€ í’ˆì§ˆì˜ sampleì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ë§ì€ iterationì´ í•„ìš”í•´ GANsë³´ë‹¤ ë§¤ìš° ëŠë¦¬ë‹¤ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/DDIM/ddim_3.jpg){: .normal}

ğŸ” DDPMê³¼ GANsì˜ gapì„ ì¤„ì´ê¸°ìœ„í•´ DDIMì„ ì œì‹œí•©ë‹ˆë‹¤.

ğŸ” DDIMì€ DDPMì˜ objective functionê³¼ ê°™ì€ objective functionì„ í†µí•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ([Section 3](#3-variational-inference-for-non-markovian-forward-process))

ğŸ” Diffusion processì—ì„œ DDPMê³¼ ë‹¬ë¦¬ non-Markovianì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ([Section 4.1]())

ğŸ” Reverse processëŠ” ê·¸ëŒ€ë¡œ Markov chainsì„ ì‚¬ìš©í•˜ëŠ”ë° ì§§ì€ Markov chains ì‚¬ìš©í•©ë‹ˆë‹¤. ([Section 4.2]())

ğŸ” DDPMë³´ë‹¤ ë‚˜ì€ ê²°ê³¼ ([Section 5]())

> 1. ë” ë‚˜ì€ í’ˆì§ˆì˜ sampleì„ ë” ë¹ ë¥¸ ì†ë„ë¡œ ìƒì„±
> 2. DDIMìœ¼ë¡œ ìƒì„±í•œ sampleì€ consistencyë¥¼ ê°€ì§€ê³  ìˆì–´ ë˜‘ê°™ì€ initial latent variableê³¼ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ Markov chainì„ í†µí•´ ìƒì„±ëœ sampleì€ ë¹„ìŠ·í•œ featureë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
> 3. Consistency ë•Œë¬¸ì— initial latent variableì„ ì¡°ì‘í•´ì„œ ì˜ë¯¸ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 2. Background

![](../../assets/img/Paper_Reading/DDIM/ddim_4.jpg){: .normal}

ğŸ’¡ í•´ë‹¹ íŒŒíŠ¸ëŠ” DDPMì— ìˆëŠ” ë‚´ìš©ì„ ë³µìŠµí•˜ëŠ” ë¶€ë¶„ì´ë¯€ë¡œ ë„˜ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

> - [Paper Reading DDPM](https://jjjuuuun.github.io/posts/Paper-Reading-DDPM/)
> - [Paper Review DDPM](https://jjjuuuun.github.io/posts/Paper-Review-DDPM/)

ğŸ’¡ ë‹¤ë§Œ, notationì´ ë‹¤ë¥¸ ë¶€ë¶„ì´ ìˆì–´ ê·¸ ë¶€ë¶„ë§Œ ë§ì”€ë“œë¦¬ê³  ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤. (DDIM $\Longrightarrow$ DDPM)

> - $\alpha\_t$ $\longrightarrow$ $\bar{\alpha}\_t$
> - ELBO termì„ ìµœëŒ€í™”í•˜ëŠ” $\theta$ë¥¼ ì°¾ëŠ” ë¬¸ì œ $\longrightarrow$ Negative ELBO termì„ ìµœì†Œí™”í•˜ëŠ” $\theta$ë¥¼ ì°¾ëŠ” ë¬¸ì œ
> - $\gamma\_t$ : ì‹œê°„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜(ê³„ìˆ˜) $\longrightarrow$ $\gamma\_t = 1$

## 3. Variational Inference For Non-Markovian Forward Process

ì§„í–‰ì¤‘ì…ë‹ˆë‹¤....
