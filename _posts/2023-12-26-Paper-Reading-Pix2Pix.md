---
layout: post
title: "[Generative Model] Pix2Pix : Image-to-Image Translation with Conditional Adversarial Networks"
author: kjy
date: 2023-12-26 16:28:00 +09:00
categories: [Deep Learning, Paper Reading]
tags: [Deep Learning, Paper Reading, Computer Vision, Generative Model]
comments: true
toc: true
math: true
---

í•´ë‹¹ í¬ìŠ¤íŠ¸ì—ì„œëŠ” [Pix2Pix : Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004) ë…¼ë¬¸ì„ í•¨ê»˜ ì½ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¬¸ì¥ë§ˆë‹¤ í•´ì„ì„ í•˜ê¸° ë³´ë‹¤ëŠ” ê° ë¬¸ë‹¨ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ìš”ì•½í•˜ëŠ” ì‹ìœ¼ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.

## Abstract

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_1.jpg){: width="400" .left}

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì€ image-to-image translation problemsì˜ general-purpose solutionì— ëŒ€í•œ conditional adversarial networksì„ ì¡°ì‚¬í•©ë‹ˆë‹¤.

ğŸ” Conditional adversarial networksëŠ” image-to-image mappingì„ í•˜ë‚˜ì˜ loss functionì„ í†µí•´ í•™ìŠµë©ë‹ˆë‹¤.

ğŸ” í•˜ë‚˜ì˜ loss functionìœ¼ë¡œ mappingì„ í•™ìŠµí•˜ëŠ” ê²ƒì´ ì´ì „ ì—°êµ¬ì™€ëŠ” ë‹¤ë¥¸ ì ì…ë‹ˆë‹¤.

ğŸ” íŠ¹íˆ í•´ë‹¹ networksëŠ” synthesizing photos from label maps, reconstructing objects from edge maps, colorizing imagesì— íš¨ê³¼ì ì¸ ì ‘ê·¼ë²•ì…ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 1. Introduction

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_2.jpg){: width="400" .left}

ğŸ” Image processing, computer graphics, computer visionì—ì„œì˜ ë§ì€ ë¬¸ì œëŠ” image-to-imageì— í•´ë‹¹í•  ê²ƒì…ë‹ˆë‹¤.

ğŸ” ì´ì „ ì—°êµ¬ì—ì„œëŠ” pixel-to-pixelì´ë¼ëŠ” ê³µí†µì ì¸ ë¶€ë¶„ì´ ìˆìŒì—ë„ ë³„ê°œì˜ ë¬¸ì œë¡œ ë‹¤ë¤˜ìŠµë‹ˆë‹¤.

ğŸ” ê·¸ë˜ì„œ í•´ë‹¹ ì—°êµ¬ì—ì„œëŠ” automatic image-to-image translationì„ ì •ì˜í•˜ê³ ì í•©ë‹ˆë‹¤.

ğŸ” í•´ë‹¹ ì—°êµ¬ì˜ ê°„ë‹¨í•œ ê²°ê³¼ëŠ” [Figure 1](#figure-1)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_3.jpg){: width="400" .left}

ğŸ” CNNì˜ learning processëŠ” ìë™ì´ì§€ë§Œ íš¨ê³¼ì ì¸ loss functionì„ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ìˆ˜ë™ì ì¸ ë…¸ë ¥ì´ í•„ìš”í•©ë‹ˆë‹¤.

ğŸ” Loss functionìœ¼ë¡œ naiveí•œ ì ‘ê·¼ë²•ì¸ Euclidean distanceë¡œ ì‚¬ìš©í•  ê²½ìš° blurryí•œ ê²°ê³¼ë¥¼ ì–»ê²Œ ë  ê²ƒì…ë‹ˆë‹¤.

ğŸ” ì™œëƒí•˜ë©´ Euclidean distanceëŠ” í‰ê· ì„ ìµœì†Œí™” í•˜ê¸° ë•Œë¬¸ì— ì „ì²´ì ìœ¼ë¡œ ê·¸ëŸ´ë“¯í•œ ê²°ê³¼ë¥¼ ë§Œë“¤ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_4.jpg){: width="400" .left}

ğŸ” í•´ë‹¹ taskì— ê°€ì¥ ë°”ëŒì§í•œ loss functionì€ GANì˜ loss functionì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” GANì˜ loss functionì€ dataì˜ ë¶„í¬ë¥¼ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— blurryí•œ ê²°ê³¼ë¥¼ í”¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ë˜í•œ GANì˜ loss functionì€ ì „í†µì ìœ¼ë¡œ ë§¤ìš° ë‹¤ë¥¸ ì¢…ë¥˜ì˜ loss functionì„ í•„ìš”ë¡œ í•˜ëŠ” ë‹¤ì–‘í•œ ì‘ì—…ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_5.jpg){: width="400" .left}

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” conditional GANsì„ ì—°êµ¬í•©ë‹ˆë‹¤.

ğŸ” ì™œëƒí•˜ë©´ ì¡°ê±´í™”ëœ ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ì£¼ê³  ê·¸ì— ëŒ€ì‘í•˜ëŠ” ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ê²ƒì´ image-to-image translationì— ì í•©í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_6.jpg){: width="400" .left}

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì˜ contributionì„ ë‘ ê°œë¡œ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ì²« ë²ˆì§¸, ë‹¤ì–‘í•œ ë¬¸ì œì—ì„œ cGANsê°€ í•©ë¦¬ì ì¸ ê²°ê³¼ë¥¼ ë„ì¶œí•  ìˆ˜ ìˆìŒì„ ì…ì¦í•©ë‹ˆë‹¤.

ğŸ” ë‘ ë²ˆì§¸, ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ ê°„ë‹¨í•œ frameworkë¥¼ ì œì‹œí•˜ê³  ëª‡ ê°€ì§€ ì¤‘ìš”í•œ architecture ì„ íƒì˜ íš¨ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 2. Related work

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_7.jpg){: width="400" .left}

ğŸ” Image-to-image translation problemì€ per pixel classification ë˜ëŠ” regressionìœ¼ë¡œ ê³µì‹í™”ë©ë‹ˆë‹¤.

ğŸ” ì´ëŸ¬í•œ ë°©ì‹ì€ unstructuredë¼ê³  output spaceë¥¼ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ cGANsëŠ” structured lossë¥¼ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì— outputê³¼ target ì‚¬ì´ì˜ ì°¨ì´ì— ë¶ˆì´ìµì„ ì£¼ë©° output spaceë¥¼ êµ¬ì¡°í™” í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_8.jpg){: width="400" .left}

ğŸ” ì´ì „ ì—°êµ¬ë“¤ì—ì„œëŠ” unconditional GANsê³¼ L2 regressionê³¼ ê°™ì€ ë‹¤ë¥¸ termì„ ì¶”ê°€í•´ image-to-image taskë¥¼ ìˆ˜í–‰í•˜ì—¬ íŠ¹ì • ë¶„ì•¼ì—ì„œ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ í•´ë‹¹ ë…¼ë¬¸ì˜ frameworkëŠ” conditional GANs ì™¸ì— ë‹¤ë¥¸ termì´ ì¶”ê°€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ğŸ” ê·¸ë ‡ê¸° ë•Œë¬¸ì— ë‹¤ë¥¸ frameworkë³´ë‹¤ ê°„ë‹¨í•˜ë‹¤ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_9.jpg){: width="400" .left}

ğŸ” ì´ì „ ì—°êµ¬ì™€ ë‹¤ë¥´ê²Œ ëª‡ëª‡ ë‹¤ë¥¸ acrhitectureë¥¼ generatorì™€ discriminatorì—ì„œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

ğŸ” Generatorì—ì„œëŠ” `U-Net`êµ¬ì¡°ì˜ architectureë¥¼ ì„ íƒí–ˆìŠµë‹ˆë‹¤.

ğŸ” Discriminatorì—ì„œëŠ” `PatchGAN`ì˜ clssifierë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

ğŸ” PatchGAN êµ¬ì¡°ê°€ ë” ë‹¤ì–‘í•œ ë²”ìœ„ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ”ë° íš¨ê³¼ì ì„ì„ í•´ë‹¹ ë…¼ë¬¸ì—ì„œ ë³´ì—¬ì¤ë‹ˆë‹¤.

ğŸ’­ Local style statisticsë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì™œ ë‹¤ì–‘í•œ ë²”ìœ„ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ”ë° ë” íš¨ê³¼ì ì¼ê¹Œ?

ğŸ’­ Patch í¬ê¸°ì— ë”°ë¥¸ ê²°ê³¼?

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 3. Method

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_10.jpg){: width="400" .left}

ğŸ” GANsê³¼ cGANsì˜ ì°¨ì´ëŠ” training images $x$ê°€ generatorì˜ ì…ë ¥ìœ¼ë¡œ random noise vector $z$ì™€ í•¨ê»˜ ë“¤ì–´ê°€ëŠ”ì§€ ì—¬ë¶€ì…ë‹ˆë‹¤.

ğŸ” GANs : $G : z \rightarrow y$

ğŸ” cGANs : $G : \\{x, z\\} \rightarrow y$

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 3.1 Objective

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_11.jpg){: width="400" .left}

ğŸ” cGANsì˜ objective functionì€ ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$\begin{align} \mathcal{L}_{cGAN}(G, D) = &\mathbb{E}_{x,y}[\log{D(x,y)}] + \\ &\mathbb{E}_{x,z}[\log{1-D(x,G(x,z))}] \end{align}$$

ğŸ” ì—¬ê¸°ì„œ $G$ëŠ” objective functionì„ ìµœëŒ€í™”í•˜ë ¤ëŠ” $D$ì— ëŒ€í•´ì„œ objective functionì„ ìµœì†Œí™”í•˜ë ¤í•©ë‹ˆë‹¤. ë”°ë¼ì„œ ì•„ë˜ì™€ ê°™ì´ $G$ì˜ objective functionì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

$$G^{*} = \text{arg}\ \text{min}_G\ \text{max}_D\ \mathcal{L}_{cGAN}(G, D)$$

ğŸ” Conditioning discriminatorì˜ ì¤‘ìš”ì„±ì„ í™•ì¸í•˜ê¸°ìœ„í•´ unconditional GANsë„ ë¹„êµí•©ë‹ˆë‹¤.

$$\begin{align} \mathcal{L}_{GAN}(G, D) = &\mathbb{E}_{y}[\log{D(y)}] + \\ &\mathbb{E}_{x, z}[\log{1-D(x,G(z))}] \end{align}$$

ğŸ” ì´ì „ ì—°êµ¬ë“¤ì²˜ëŸ¼ L2 regressionê³¼ ê°™ì€ termì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë” íš¨ê³¼ì ì¸ì§€ í•´ë‹¹ ë…¼ë¬¸ì—ì„œ í™•ì¸í•©ë‹ˆë‹¤. ê·¸ ì¤‘ì—ì„œ blurringì´ ëœ í•œ L1 distanceë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

$$\mathcal{L}_{L1}(G) = \mathbb{E}_{x,y,z}[||y - G(x,z)||_1]$$

ğŸ” ìµœì¢… objective functionì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

$$G^{*} = \text{arg}\ \underset{G}{\text{min}}\ \underset{D}{\text{max}}\ \mathcal{L}_{cGAN}(G, D) + \lambda\mathcal{L}_{L1}(G)$$

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_12.jpg){: width="400" .left}

ğŸ” Random noise vector $z$ê°€ ì—†ì„ ë•Œ ì—¬ì „íˆ $x \rightarrow y$ë¥¼ í•™ìŠµí•˜ì§€ë§Œ deterministic outputsì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.

ğŸ” Deterministic outputsì´ë€, ë™ì¼í•œ xê°€ ì£¼ì–´ì¡Œì„ ë•Œ ë™ì¼í•œ outputì´ ë‚˜ì˜¨ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤. ì´ê²ƒì„ í™•ë¥ ë¶„í¬ ê´€ì ì—ì„œ ë³¸ë‹¤ë©´ delta function ì™¸ì— ì–´ë– í•œ ë¶„í¬ì™€ë„ ë§¤ì¹­ì´ë˜ì§€ ì•ŠëŠ” ê²ƒì„ ë§í•©ë‹ˆë‹¤.

ğŸ” ì´ˆê¸° ì‹¤í—˜ì—ì„œëŠ” random noise vector $z$ì˜ ì—­í• ì´ ë³´ì´ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ í•´ë‹¹ ë…¼ë¬¸ì˜ ìµœì¢… ëª¨ë¸ì—ì„œëŠ” random noise vector $z$ê°€ dropout í˜•íƒœë¡œ generatorì—ê²Œ ì˜í–¥ì„ ì£¼ê³  ìˆëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

ğŸ” ì´ëŸ° random noise vector $z$ê°€ ì‘ì€ í™•ë¥ ì  ë³€í™”ë¥¼ ë§Œë“¤ì–´ë‚¸ ê²ƒì„ ì•Œ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

ğŸ” ë§ì€ í™•ë¥ ì  ë³€í™”ë¥¼ ë§Œë“¤ì–´ ë‚´ë„ë¡ cGANsë¥¼ ì„¤ê³„í•˜ëŠ” ê²ƒì´ ì¶”í›„ ì—°êµ¬ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 3.2 Network architecture

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_13.jpg){: width="400" .left}

ğŸ” Generatorì™€ Discriminatorì˜ êµ¬ì¡°ëŠ” DCGANì˜ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ” Convolution / BatchNorm / ReLU ë¡œ ì´ë£¨ì–´ì§„ ëª¨ë“ˆë“¤ë¡œ êµ¬ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

#### 3.2.1 Generator with skips

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_14.jpg){: width="400" .left}

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì˜ ì €ìë“¤ì´ ì–´ë–¤ ì ì„ ì—¼ë‘í•˜ë©´ì„œ generatorë¥¼ êµ¬ì„±í–ˆëŠ”ì§€ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” Image-to-image translation problemsëŠ” high resolutionì—ì„œ high resolutionìœ¼ë¡œ mappingí•˜ëŠ” ê²ƒìœ¼ë¡œ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ë˜í•œ inputê³¼ outputì„ ì„œë¡œ ë‹¤ë¥¸ surfaceë¥¼ ë³´ì´ì§€ë§Œ ë‘˜ ë‹¤ ë¹„ìŠ·í•œ êµ¬ì¡°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ” ì´ëŸ¬í•œ ì ì„ ê³ ë ¤í•´ generatorë¥¼ êµ¬ì„±í–ˆë‹¤ê³  í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_15.jpg){: width="400" .left}

ğŸ” ë§ì€ ì´ì „ì˜ ì—°êµ¬ë“¤ì€ encoder-decoder êµ¬ì¡°ë¥¼ ì‚¬ìš©í–ˆìœ¼ë©° ëª¨ë“  ì •ë³´ê°€ ëª¨ë“  layerë¥¼ ì§€ë‚˜ê°€ë©° ì „ë‹¬ë˜ë„ë¡ í•©ë‹ˆë‹¤.

ğŸ” Image translation problemì—ì„œ inputê³¼ output ì‚¬ì´ì— ê³µìœ ë˜ëŠ” low-level informationì´ ë§ì´ ìˆìŠµë‹ˆë‹¤.

ğŸ” ê·¸ë ‡ê¸° ë•Œë¬¸ì— networkì— low-level informationì„ ì§ì ‘ ì „ë‹¬í•˜ëŠ” ê²ƒì´ ë°”ëŒì§í•©ë‹ˆë‹¤.

ğŸ¤” ìœ„ì—ì„œ ë³¸ ê²ƒì²˜ëŸ¼ inputê³¼ outputì˜ êµ¬ì¡°ëŠ” ë¹„ìŠ·í•˜ë¯€ë¡œ inputê³¼ output ì‚¬ì´ì— ë§ì´ ê³µìœ ë˜ëŠ” low-level informationì„ ë”ìš± ì˜ í™œìš©í•  ìˆ˜ ìˆë‹¤ë©´ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì´ë‹¤ë¼ëŠ” ìƒê°ì—ì„œ low-level informationì„ ì§ì ‘ networkì— ì „ë‹¬í•œ ê²ƒì´ ì•„ë‹ê¹Œ ìƒê°í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_16.jpg){: width="400" .left}

ğŸ” ì´ ëª¨ë“  ê²ƒì„ ì¢…í•©í–ˆì„ ë•Œ generatorëŠ” U-Net êµ¬ì¡°ë¥¼ ê°€ì§‘ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

#### 3.2.2 Markovian discriminator (PatchGAN)

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_17.jpg){: width="400" .left}

ğŸ” ì´ì „ ì—°êµ¬ë“¤ì—ì„œ ì‚¬ìš©ë˜ì–´ ì˜¨ L2 loss ë˜ëŠ” L1 lossë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ blurryí•œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ ë‚´ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.([Figure 4](#figure-4))

ğŸ” ì´ëŸ¬í•œ lossëŠ” high frequencyë¥¼ ì˜ ë‚˜íƒ€ë‚´ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì— blurryí•œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë‚´ì§€ë§Œ low frequencyëŠ” ì˜ íŒŒì•…í•©ë‹ˆë‹¤.

ğŸ” ê·¸ë ‡ê¸° ë•Œë¬¸ì— low frequencyë¥¼ ë‚˜íƒ€ë‚´ê¸° ìœ„í•´ ì¶”ê°€ì ì¸ frameworkì´ í•„ìš”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_18.jpg){: width="400" .left}

ğŸ” Low frequencyëŠ” L1 lossë¡œ ì¶©ë¶„íˆ íŒŒì•…í•˜ê¸° ë•Œë¬¸ì— discriminatorëŠ” high frequencyë§Œ ì˜ íŒŒì•…í•˜ë„ë¡ ì„¤ê³„í•˜ë©´ ë©ë‹ˆë‹¤.

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” high frequencyë¥¼ ì˜ íŒŒì•…í•˜ê¸° ìœ„í•œ ë°©ë²•ìœ¼ë¡œ `PatchGAN`ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

ğŸ” Patchë“¤ì˜ real or fakeë¥¼ êµ¬ë¶„í•˜ê³  ëª¨ë“  patchë“¤ì˜ í‰ê· ì„ discriminatorì˜ outputìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_19.jpg){: width="400" .left}

ğŸ” Patch size $N$ì´ image sizeë³´ë‹¤ ì‘ì€ ê²½ìš° ì¢‹ì€ í’ˆì§ˆì˜ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆìŒì„ í•´ë‹¹ ë…¼ë¬¸ì—ì„œ ì…ì¦í•©ë‹ˆë‹¤.

ğŸ’­ Patch sizeì— ë”°ë¥¸ ê²°ê³¼?

ğŸ” Patch size $N$ì´ ì‘ì„ìˆ˜ë¡ ë” ì ì€ íŒŒë¼ë¯¸í„°, ë” ë¹ ë¥¸ ì†ë„, í° ì´ë¯¸ì§€ì— ì ìš©í•  ìˆ˜ ìˆë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_20.jpg){: width="400" .left}

ğŸ” PatchGANì˜ discriminatorëŠ” ì´ë¯¸ì§€ë¥¼ Markov random fieldë¡œ ìƒê°í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

ğŸ” Markov random fieldëŠ” texture, style modelì—ì„œ í”í•œ ê°€ì •ì…ë‹ˆë‹¤.

ğŸ” ë”°ë¼ì„œ PatchGANì€ texture/style lossì˜ í•œ í˜•íƒœë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 3.3 Optimization and inference

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_21.jpg){: width="400" .left}

ğŸ” í•™ìŠµ ë°©ë²•ì„ ì†Œê°œí•©ë‹ˆë‹¤.

ğŸ” $D$ë¥¼ í•œ ë²ˆ updateí•˜ê³  $G$ë¥¼ update í•©ë‹ˆë‹¤.

ğŸ” $\log(1-D(x,G(x,z)))$ë¥¼ ìµœì†Œí™”í•˜ëŠ” ëŒ€ì‹  $\log D(x,G(x,z))$ë¥¼ ìµœëŒ€í™”í•©ë‹ˆë‹¤.

ğŸ” $D$ë¥¼ update í•  ë•Œ 2ë¡œ ë‚˜ëˆ  í•™ìŠµ ì†ë„ë¥¼ ëŠ¦ì¶¥ë‹ˆë‹¤.

ğŸ” Minibatch SGDë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

ğŸ” Adam($lr = 0.0002,\ \beta_1=0.5,\ \beta_2=0.999$)

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_22.jpg){: width="400" .left}

ğŸ” Inference timeì—ëŠ” trainingë•Œ ì‚¬ìš©í•œ generatorë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ íŠ¹ì´í•œ ì ìœ¼ë¡œëŠ” test timeì—ì„œë„ dropoutì„ ì ìš©í•œë‹¤ëŠ” ì ì…ë‹ˆë‹¤.

ğŸ” ê·¸ë¦¬ê³  batch normalizationì„ ì‚¬ìš©í–ˆëŠ”ë° training dataì˜ statisticsê°€ ì•„ë‹Œ test dataì˜ statisticsë¥¼ ì‚¬ìš©í•œ ê²ƒ ë˜í•œ íŠ¹ì´í•œ ì ì…ë‹ˆë‹¤.

ğŸ” ìœ„ì—ì„œ ë§í•œ batch normalizationì˜ batch sizeê°€ $1$ì¸ ê²½ìš°ë¥¼ instance normalizationì´ë¼ê³  ë³¼ ìˆ˜ ìˆìœ¼ë©° generation taskì—ì„œ ê°€ì¥ íš¨ê³¼ì ì¸ normalizationì´ë¼ê³  í•©ë‹ˆë‹¤.

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” inference timeì— batch sizeë¥¼ $1 \sim 10$ìœ¼ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## 4. Experiments

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_23.jpg){: width="400" .left}

ğŸ” ì‹¤í—˜ì— ì‚¬ìš©ëœ pair-datasetì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_24.jpg){: width="400" .left}

ğŸ” ì¢‹ì€ í€„ë¦¬í‹°ì˜ ê²°ê³¼ë¬¼ê³¼ ì‹¤íŒ¨í•œ ê²°ê³¼ë¬¼ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_25.jpg){: width="400" .left}

ğŸ” ì‘ì€ datasetì—ì„œë„ ì¢…ì¢… ê´œì°®ì€ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

ğŸ” Training datasetì´ 400ê°œ

ğŸ” Training datasetì´ 91ê°œ

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 4.1 Evaluation metrics

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_26.jpg){: width="400" .left}

ğŸ” Per-pixel MSEì™€ ê°™ì€ ì „í†µì ì¸ metricsì˜ ê²½ìš° ê²°ê³¼ë¬¼ì˜ ê³µí†µì ì¸ í†µê³„ì¹˜ì— ì ‘ê·¼í•  ìˆ˜ ì—†ì–´ì„œ êµ¬ì¡°ì ì¸ ì¸¡ì •ì„ í•  ìˆ˜ ì—†ì—ˆìŠµë‹ˆë‹¤.

ğŸ” ê·¸ë˜ì„œ ì „ì²´ì ìœ¼ë¡œ íŒŒì•…í•˜ê³ ì ë‘ ê°€ì§€ metricì„ ë„ì…í–ˆìŠµë‹ˆë‹¤.

ğŸ” ì²« ë²ˆì§¸, realì¸ì§€ fakeì¸ì§€ ì‚¬ëŒì´ êµ¬ë¶„

ğŸ” ë‘ ë²ˆì§¸, ë§Œë“¤ì–´ì§„ ê²°ê³¼ë¬¼ì´ ì¶©ë¶„íˆ í˜„ì‹¤ì ì¸ì§€ ì¸¡ì •

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_27.jpg){: width="400" .left}

ğŸ” ì²« ë²ˆì§¸, realì¸ì§€ fakeì¸ì§€ ì‚¬ëŒì´ êµ¬ë¶„í•˜ê¸°ìœ„í•´ AMT ì‹¤í—˜ ì§„í–‰

ğŸ” Fakeì¸ì§€ realì¸ì§€ êµ¬ë¶„í•˜ê¸° ìœ„í•´ í•˜ë‚˜ì˜ fake ì´ë¯¸ì§€ì™€ í•˜ë‚˜ì˜ real ì´ë¯¸ì§€ë¥¼ í•¨ê»˜ 1ì´ˆë™ì•ˆë§Œ ë³´ì—¬ì£¼ê³  ì–´ë–¤ ê²ƒì´ fakeì¸ì§€ ì‘ë‹µí•  ìˆ˜ ìˆëŠ” ì‹œê°„ì´ ë¬´ì œí•œìœ¼ë¡œ ì£¼ì–´ì¡ŒìŠµë‹ˆë‹¤.

ğŸ” í‰ê°€ìë“¤ì€ í•˜ë‚˜ì˜ ì„¸ì…˜ë§Œ í‰ê°€í•  ìˆ˜ ìˆì—ˆìœ¼ë©° ê° ì„¸ì…˜ì€ ì„œë¡œ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§„ ê²°ê³¼ë¬¼ì„ ë¹„êµí•©ë‹ˆë‹¤.

ğŸ” ë˜í•œ ê° ì„¸ì…˜ì—ì„œ ì²« 10ì¥ì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œëŠ” í”¼ë“œë°±ì„ ì£¼ëŠ” ì—°ìŠµ ì´ë¯¸ì§€ì´ê³  ë‚˜ë¨¸ì§€ 40ì¥ì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ì„œ í‰ê°€ë¥¼ ì§„í–‰í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_28.jpg){: width="400" .left}

ğŸ” ë‘ ë²ˆì§¸, ë§Œë“¤ì–´ì§„ ê²°ê³¼ë¬¼ì´ ì¶©ë¶„íˆ í˜„ì‹¤ì ì¸ì§€ ì¸¡ì •í•˜ê¸°ìœ„í•´ FCN-score ì¸¡ì •

ğŸ” ë§Œë“¤ì–´ì§„ ì´ë¯¸ì§€ê°€ í˜„ì‹¤ì ì´ë¼ë©´ real imagesë¡œ í•™ìŠµëœ semantic classifierê°€ ì˜ ë¶„ë¥˜í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.

ğŸ” ì´ëŸ¬í•œ ê´€ì ì—ì„œ semantic semgentationì—ì„œ ê°€ì¥ ìœ ëª…í•œ `FCN-8s`ë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 4.2 Analysis of the objective function

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_29.jpg){: width="400" .left}

ğŸ” [Figure 4](#figure-4) ê²°ê³¼ ë¶„ì„

ğŸ” L1 lossë§Œ ì‚¬ìš©í–ˆì„ ë•Œ : Blurryí•œ ê²°ê³¼

ğŸ” cGANsë§Œ ì‚¬ìš©í–ˆì„ ë•Œ : L1 lossë§Œ ì‚¬ìš©í–ˆì„ ë•Œë³´ë‹¤ëŠ” sharpí•œ ê²°ê³¼ì´ì§€ë§Œ ëª‡ëª‡ ê²°ê³¼ì—ì„œ artifacts ë°œê²¬

ğŸ” L1 + cGANs : Artifactsë¥¼ ì¤„ì„

ğŸ” [Table 1](#table-1) ê²°ê³¼ ë¶„ì„

ğŸ” L1 VS cGAN : cGANì˜ ì„±ëŠ¥ì´ ë” ì¢‹ìŒ

ğŸ” Unconditional GANsë¥¼ ì‚¬ìš©í–ˆì„ ë•Œ input ì´ë¯¸ì§€ì™€ ê´€ê³„ì—†ì´ í˜„ì‹¤ì ì¸ ì´ë¯¸ì§€ë§Œì„ ìƒì„±í•˜ë ¤ëŠ” ê²½í–¥ì„ ë³´ì´ë©° input ì´ë¯¸ì§€ì™€ ê´€ë ¨ì—†ì´ ê°™ì€ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” collapse í˜„ìƒì´ ë°œìƒí•˜ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

ğŸ” ì´ëŸ¬í•œ í˜„ìƒì„ cGANsë¥¼ í†µí•´ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ë˜í•œ L1 lossëŠ” ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ì˜ ê±°ë¦¬ì— penaltyë¥¼ ì£¼ê¸° ë•Œë¬¸ì— collapse í˜„ìƒì„ í•´ê²°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ìµœì¢…ì ìœ¼ë¡œ cGANs + L1 lossë¥¼ í†µí•´ collapse í˜„ìƒì„ íš¨ê³¼ì ìœ¼ë¡œ í•´ê²°í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_30.jpg){: width="400" .left}

ğŸ” [Figure 7](#figure-1) : ìƒ‰ ì¸¡ë©´ì—ì„œ L1 lossì™€ cGANsì˜ ì°¨ì´ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

ğŸ” L1 : Pixelì´ ê·¸ëŸ´ë“¯í•œ ìƒ‰ìƒ ì¤‘ ì–´ëŠ ê²ƒì„ ì„ íƒí•´ì•¼í• ì§€ ë¶ˆí™•ì‹¤í•  ë•Œ L1 lossë¥¼ ìµœì†Œí™”í•˜ê¸° ìœ„í•´ ì¡°ê±´ë¶€ í™•ë¥ ë°€ë„í•¨ìˆ˜ì˜ ì¤‘ì•™ê°’ì„ ì„ íƒí•˜ê²Œ ë˜ëŠ”ë° ì´ ë•Œ ì¤‘ì•™ê°’ì€ íšŒìƒ‰ì…ë‹ˆë‹¤.

ğŸ” cGANs : íšŒìƒ‰ì˜ pixelì€ ë¹„í˜„ì‹¤ì ì¸ ê²ƒì„ ì¸ì‹í•˜ê³  ì‹¤ì œ ìƒ‰ìƒ ë¶„í¬ì™€ ì¼ì¹˜í•˜ë„ë¡ í•˜ê¸° ë•Œë¬¸ì— ì´ë¯¸ì§€ë¥¼ ë”ìš± colorfulí•˜ê²Œ ë§Œë“œëŠ” íš¨ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 4.3 Analysis of the generator architecture

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_31.jpg){: width="400" .left}

ğŸ” U-Net architectureê°€ ì •ë§ íš¨ê³¼ì ì¸ì§€ ì‹¤í—˜í•©ë‹ˆë‹¤.

ğŸ” [Figure 5](#figure-5)ì—ì„œ L1ë§Œ ì‚¬ìš©í–ˆì„ ë•Œì—ë„ U-Net architectureê°€ ë” ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ë”°ë¼ì„œ U-Net architectureê°€ cGANsì—ë§Œ êµ­í•œë˜ëŠ” ì´ì ì€ ì•„ë‹Œ ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 4.4 From PixelGANs to Patch GANs to ImageGANs

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_32.jpg){: width="400" .left}

ğŸ” Patch size($N$)ì— ë”°ë¥¸ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

ğŸ” PixelGAN($N = 1$) : No sharpness / colorful

ğŸ” PatchGAN($N = 16$) : Artifacts / Sharpness & Good FCN-scores

ğŸ” PatchGAN($N = 70$) : Artifacts ì™„í™” / Sharpness & Good FCN-scores

ğŸ” ImageGAN($N = 286$) : ê²°ê³¼ë¬¼ì„ ì§ì ‘ ë´ë„ ì¢‹ì§€ ì•ŠìŒ & Bad FCN-scores / âŒ

ğŸ” ImageGANì´ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ì§€ ëª»í•œ ì´ìœ ë¡œ ì¦ê°€í•œ parameterë¡œ ì¸í•œ ì–´ë ¤ìš´ í•™ìŠµì„ ì´ì•¼ê¸° í–ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_33.jpg){: width="400" .left}

ğŸ” PatchGANì˜ ì¥ì ì€ ê³ ì •ëœ patch sizeë¡œ ë” í° ì´ë¯¸ì§€ì— ì ìš©í•  ìˆ˜ ìˆëŠ” ê²ƒì…ë‹ˆë‹¤.

ğŸ” $256 \times 256$ì¸ ì´ë¯¸ì§€ë¡œ generatorë¥¼ í•™ìŠµí•œ ì´í›„ $512 \times 512$ì¸ ì´ë¯¸ì§€ë¡œ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•œ ê²°ê³¼ë¥¼ [Figure 8](#figure-8)ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 4.5 Perceptual validation

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_34.jpg){: width="400" .left}

ğŸ” Map $\rightarrow$ Photoì—ì„œ ë§ì€ í–¥ìƒì„ ë³´ì˜€ì§€ë§Œ ì—¬ì „íˆ ë¶€ì¡±í•œ ìˆ˜ì¹˜ì…ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_35.jpg){: width="400" .left}

ğŸ” Colorizationì— ëŒ€í•´ AMT ì‹¤í—˜ì„ ì§„í–‰í–ˆì§€ë§Œ coloriationì— íŠ¹í™”ëœ ì—°êµ¬ë³´ë‹¤ëŠ” ë‚®ì€ ê²°ê³¼ë¥¼ ì–»ì—ˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### 4.6 Semantic segmentation

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_36.jpg){: width="400" .left}

ğŸ” cGANsëŠ” outputì´ ìƒì„¸í•œ ê²½ìš°ì— íš¨ê³¼ì ì¸ ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚˜ëŠ”ë° ê·¸ë ‡ë‹¤ë©´ outputì´ inputë³´ë‹¤ ëœ ë³µì¡í•œ semantic segmentationê³¼ ê°™ì€ ë¬¸ì œëŠ” ì–´ë–¨ê¹Œìš”?ì— ëŒ€í•´ ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.

ğŸ” L1 lossë§Œ ì‚¬ìš©í•œ ê²½ìš°ê°€ ê°€ì¥ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì—¬ì£¼ëŠ” ê²ƒì„ í™•ì¸í–ˆìŠµë‹ˆë‹¤. ë°˜ëŒ€ë¡œ cGANsë¥¼ ê°™ì´ ì‚¬ìš©í•œ ê²½ìš° ê²°ê³¼ê°’ì€ ê°ì†Œí•©ë‹ˆë‹¤.([Figure 10](#figure-10), [Table 6](#table-6))

ğŸ” ì´ì‚°ì ì¸ labelë¥¼ ìƒì„±í•œ ì²« ì‚¬ë¡€

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## Figure

### Figure 1

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f1.jpg){: width="400" .left}

ğŸ” ê°™ì€ architecture, objectiveì™€ ì„œë¡œ ë‹¤ë¥¸ training dataë¥¼ ì‚¬ìš©í•´ í•™ìŠµí•œ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 2

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f2.jpg){: width="400" .left}

ğŸ” GANsê³¼ ë‹¬ë¦¬ cGANsì—ì„œëŠ” generatorì™€ discriminator ëª¨ë‘ì— input image $x$ê°€ ë“¤ì–´ê°€ëŠ” ê²ƒì„ ê·¸ë¦¼ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 3

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f3.jpg){: width="400" .left}

ğŸ” Encoder-Decoder êµ¬ì¡°ì™€ U-Net êµ¬ì¡°ë¥¼ ê·¸ë¦¼ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.

ğŸ” U-Net êµ¬ì¡°ê°€ skip connectionsì´ í¬í•¨ëœ encoder-decoder êµ¬ì¡°ì„ì„ ë§í•˜ê³  ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 4

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f4.jpg){: width="400" .left}

ğŸ” L1 lossê°€ blurryí•œ ê²°ê³¼ë¥¼ ë§Œë“¤ì–´ë‚´ëŠ” ê²ƒì„ ê·¸ë¦¼ìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 5

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f5.jpg){: width="400" .left}

ğŸ” Encoder-decoder VS U-Net architectureì˜ ê²°ê³¼ë¬¼ì„ ë¹„êµí•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 6

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f6.jpg){: width="400" .left}

ğŸ” Patch size($N$)ì— ë”°ë¥¸ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 7

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f7.jpg){: width="400" .left}

ğŸ” L, a, bë¥¼ í†µí•´ ìƒ‰ì„ í‘œí˜„í•˜ëŠ” ê²ƒì„ CIELABë¼ê³  í•©ë‹ˆë‹¤.

ğŸ” Lì€ ë°ê¸°ë¥¼ ë‚˜íƒ€ë‚´ë©° 0 ~ 100ì˜ ë²”ìœ„ë¥¼ ê°€ì§€ê³  0ì€ ì™„ì „íˆ ì–´ë‘ìš´ ê²€ì€ìƒ‰, 100ì€ ì™„ì „íˆ ë°ì€ í°ìƒ‰ì„ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

ğŸ” aëŠ” ë…¹ìƒ‰ì—ì„œ ë¹¨ê°„ìƒ‰ìœ¼ë¡œì˜ ìƒ‰ìƒ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ë©° ìŒìˆ˜ëŠ” ë…¹ìƒ‰, ì–‘ìˆ˜ëŠ” ë¹¨ê°„ìƒ‰, 0ì€ íšŒìƒ‰ì…ë‹ˆë‹¤.

ğŸ” bëŠ” íŒŒë€ìƒ‰ì—ì„œ ë…¸ë€ìƒ‰ìœ¼ë¡œì˜ ìƒ‰ìƒ ì°¨ì´ë¥¼ ë‚˜íƒ€ë‚´ë©° ìŒìˆ˜ëŠ” íŒŒë€ìƒ‰, ì–‘ìˆ˜ëŠ” ë…¸ë€ìƒ‰, 0ì€ íšŒìƒ‰ì…ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 8

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f8.jpg){: width="400" .left}

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 9

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f9.jpg){: width="400" .left}

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Figure 10

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f10.jpg){: width="400" .left}

![](../../assets/img/Paper_Reading/blank.png){: .normal}

## Table

### Table 1

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_t1.jpg){: width="400" .left}

ğŸ” L1 lossì™€ GANs, cGANsì˜ ablation studiesì˜ ê²°ê³¼ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Table 2

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_t2.jpg){: width="400" .left}

ğŸ” Encoder-decoder VS U-Net architectureì˜ FCN-scoreë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Table 3

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_t3.jpg){: width="400" .left}

ğŸ” Patch size($N$)ì— ë”°ë¥¸ FCN-scoresë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Table 4

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_t4.jpg){: width="400" .left}

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Table 5

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_t5.jpg){: width="400" .left}

![](../../assets/img/Paper_Reading/blank.png){: .normal}

### Table 6

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_t6.jpg){: width="400" .left}

![](../../assets/img/Paper_Reading/blank.png){: .normal}
