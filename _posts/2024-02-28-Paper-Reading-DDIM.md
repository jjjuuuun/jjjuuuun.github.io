---
layout: post
title: "[Generative Model] DDIM : Denoising Diffusion Implicit Models"
author: kjy
date: 2024-02-28 22:30:00 +09:00
categories: [Deep Learning, Paper Reading]
tags: [Deep Learning, Paper Reading, Computer Vision, Generative Model]
comments: true
toc: true
math: true
---

í•´ë‹¹ í¬ìŠ¤íŠ¸ì—ì„œëŠ” [DDIM : Denoising Diffusion Implicit Models](https://arxiv.org/abs/2010.02502) ë…¼ë¬¸ì„ í•¨ê»˜ ì½ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤. ë¬¸ì¥ë§ˆë‹¤ í•´ì„ì„ í•˜ê¸° ë³´ë‹¤ëŠ” ê° ë¬¸ë‹¨ì—ì„œ ì¤‘ìš”í•œ ë¶€ë¶„ì„ ìš”ì•½í•˜ëŠ” ì‹ìœ¼ë¡œ ì§„í–‰í•˜ê² ìŠµë‹ˆë‹¤.

Emojiì˜ ì˜ë¯¸ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

ğŸ” : ë…¼ë¬¸ì— ìˆëŠ” ë‚´ìš©

ğŸ’¡ : ë…¼ë¬¸ì— ì í˜€ìˆì§€ ì•Šì€ ì‚¬ì „ì§€ì‹

ğŸ’­ : ì €ì˜ ìƒê°

â­ : ì¤‘ìš”í•œ ë‚´ìš©

âœ… : ë‚˜ì¤‘ì— í™•ì¸ì´ í•„ìš”í•œ ë‚´ìš©

## Abstract

![](../../assets/img/Paper_Reading/DDIM/ddim_1.jpg){: .normal}

ğŸ” DDPMì˜ ë‹¨ì  : Sampleì„ ìƒì„±í•˜ê¸°ìœ„í•´ ë§ì€ stepì˜ Markov chain ê³¼ì •ì„ ê±°ì³ì•¼ í•©ë‹ˆë‹¤.

ğŸ” DDIM : DDPMê³¼ ê°™ì€ objective functionì„ ë§Œë“œëŠ” non-Markovian diffusion processë¥¼ í†µí•´ í•™ìŠµ

> ğŸ” 10 ~ 50ë°° ì •ë„ DDPMë³´ë‹¤ ë¹ ë¦…ë‹ˆë‹¤.  
> ğŸ” Semantically meaningful imageë¥¼ latent spaceì—ì„œ ë°”ë¡œ interpolationì„ í†µí•´ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.  
> ğŸ” ë§¤ìš° ë‚®ì€ reconstruction errorë¥¼ ê´€ì°°í–ˆìŠµë‹ˆë‹¤.

## 1. Introduction

![](../../assets/img/Paper_Reading/DDIM/ddim_2.jpg){: .normal}

ğŸ” Generative model : GANs, VAE, Autoregressive models, normalizaing flows

ğŸ” ê·¸ ì¤‘ GANsì´ ê°€ì¥ ì¢‹ì€ í’ˆì§ˆì„ ë§Œë“¤ì–´ëƒˆì§€ë§Œ í•™ìŠµ ì•ˆì •í™”ë¥¼ í•˜ê¸° ìœ„í•´ ë§¤ìš° ì‹ ì¤‘í•œ optimizationê³¼ architecture ì„ íƒì´ í•„ìš”í•©ë‹ˆë‹¤.

ğŸ” ìµœê·¼ì—ëŠ” iterative generative modelsì— ëŒ€í•œ ì—°êµ¬ê°€ ì§„í–‰(DDPM, NCSN)

ğŸ” Iterative generative modelì€ GANsê³¼ ê²¬ì¤„ë§Œí•œ í’ˆì§ˆì„ ìƒì„±í–ˆìœ¼ë©° GANsì— ë¹„í•´ í•™ìŠµì´ ì‰½ë‹¤ëŠ” ì¥ì ì´ ìˆìŠµë‹ˆë‹¤.

ğŸ” ê·¸ëŸ¬ë‚˜ ë†’ì€ í’ˆì§ˆì˜ sampleì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ë§ì€ iterationì´ í•„ìš”í•´ GANsë³´ë‹¤ ë§¤ìš° ëŠë¦¬ë‹¤ëŠ” ë‹¨ì ì´ ìˆìŠµë‹ˆë‹¤.

![](../../assets/img/Paper_Reading/DDIM/ddim_3.jpg){: .normal}

ğŸ” DDPMê³¼ GANsì˜ gapì„ ì¤„ì´ê¸°ìœ„í•´ DDIMì„ ì œì‹œí•©ë‹ˆë‹¤.

ğŸ” DDIMì€ DDPMì˜ objective functionê³¼ ê°™ì€ objective functionì„ í†µí•´ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤. ([Section 3](#3-variational-inference-for-non-markovian-forward-process))

ğŸ” Diffusion processì—ì„œ DDPMê³¼ ë‹¬ë¦¬ non-Markovianì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ([Section 4.1]())

ğŸ” Reverse processëŠ” ê·¸ëŒ€ë¡œ Markov chainsì„ ì‚¬ìš©í•˜ëŠ”ë° ì§§ì€ Markov chains ì‚¬ìš©í•©ë‹ˆë‹¤. ([Section 4.2]())

ğŸ” DDPMë³´ë‹¤ ë‚˜ì€ ê²°ê³¼ ([Section 5]())

> 1. ë” ë‚˜ì€ í’ˆì§ˆì˜ sampleì„ ë” ë¹ ë¥¸ ì†ë„ë¡œ ìƒì„±
> 2. DDIMìœ¼ë¡œ ìƒì„±í•œ sampleì€ consistencyë¥¼ ê°€ì§€ê³  ìˆì–´ ë˜‘ê°™ì€ initial latent variableê³¼ ë‹¤ì–‘í•œ ê¸¸ì´ì˜ Markov chainì„ í†µí•´ ìƒì„±ëœ sampleì€ ë¹„ìŠ·í•œ featureë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.
> 3. Consistency ë•Œë¬¸ì— initial latent variableì„ ì¡°ì‘í•´ì„œ ì˜ë¯¸ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## 2. Background

![](../../assets/img/Paper_Reading/DDIM/ddim_4.jpg){: .normal}

ğŸ’¡ í•´ë‹¹ íŒŒíŠ¸ëŠ” DDPMì— ìˆëŠ” ë‚´ìš©ì„ ë³µìŠµí•˜ëŠ” ë¶€ë¶„ì´ë¯€ë¡œ ë„˜ì–´ê°€ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

> - [Paper Reading DDPM](https://jjjuuuun.github.io/posts/Paper-Reading-DDPM/)
> - [Paper Review DDPM](https://jjjuuuun.github.io/posts/Paper-Review-DDPM/)

ğŸ’¡ ë‹¤ë§Œ, notationì´ ë‹¤ë¥¸ ë¶€ë¶„ì´ ìˆì–´ ê·¸ ë¶€ë¶„ë§Œ ë§ì”€ë“œë¦¬ê³  ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤. (DDIM $\Longrightarrow$ DDPM)

> - $\alpha\_t$ $\longrightarrow$ $\bar{\alpha}\_t$
> - ELBO termì„ ìµœëŒ€í™”í•˜ëŠ” $\theta$ë¥¼ ì°¾ëŠ” ë¬¸ì œ $\longrightarrow$ Negative ELBO termì„ ìµœì†Œí™”í•˜ëŠ” $\theta$ë¥¼ ì°¾ëŠ” ë¬¸ì œ
> - $\gamma\_t$ : ì‹œê°„ì— ë”°ë¥¸ ê°€ì¤‘ì¹˜(ê³„ìˆ˜) $\longrightarrow$ $\gamma\_t = 1$

## 3. Variational Inference For Non-Markovian Forward Process

![](../../assets/img/Paper_Reading/DDIM/ddim_5.jpg){: .normal}

ğŸ” Generative modelì€ reverse of inference processì„ approximate

- Inference process : Diffusion process / Forward process
- Reverse of inference process : Denoising process / Reverse process

ğŸ” Generative modelì´ imageë¥¼ ìƒì„±í•˜ê¸° ìœ„í•´ í•„ìš”í•œ iteration ìˆ˜ë¥¼ ì¤„ì´ê¸° ìœ„í•´ inference processë¥¼ ë‹¤ì‹œ ìƒê°í•  í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.

ğŸ” DDPMì˜ objectiveì¸ $L\_\gamma$ëŠ” marginals $q(\mathbf{x}\_t\|\mathbf{x}\_0)$ì—ë§Œ ì˜ì¡´í•˜ê³  joints $q(\mathbf{x}\_{1:T}\|\mathbf{x}\_0)$ì—ëŠ” ì§ì ‘ ì˜ì¡´í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

$$
\begin{align}
L_\gamma(\epsilon_\theta)
:=& \sum^T_{t=1}\gamma_t\mathbb{E}_{\mathbf{x}_0\sim q(\mathbf{x}_0), \epsilon_T \sim \mathcal{N}(\mathrm{0}, \mathrm{I})}\Big[ \lVert \epsilon^{(t)}_\theta {\color{Red}\mathbf{x}_t}\ -\ \epsilon_t \rVert^2_2 \Big] & \qquad \\
=& \sum^T_{t=1}\gamma_t\mathbb{E}_{\mathbf{x}_0\sim q(\mathbf{x}_0), \epsilon_T \sim \mathcal{N}(\mathrm{0}, \mathrm{I})}\Big[ \lVert \epsilon^{(t)}_\theta (\sqrt{\alpha_t}{\color{Red}\mathbf{x}_0}\ +\ \sqrt{1-\alpha_t}\epsilon_t)\ -\ \epsilon_t \rVert^2_2 \Big] & \qquad \because \mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_0\ +\ \sqrt{1-\alpha_t}\epsilon_t
\end{align}
$$

ğŸ” ê°™ì€ marginals $q(\mathbf{x}\_t\|\mathbf{x}\_0)$ì„ ê°€ì§€ëŠ” joints $q(\mathbf{x}\_{1:T}\|\mathbf{x}\_0)$ê°€ ë§ê¸° ë•Œë¬¸ì— Non-Markovian inference processë¥¼ íƒìƒ‰í•˜ì—¬ ìƒˆë¡œìš´ generative processë¡œ ì´ì–´ì§€ë„ë¡ í•©ë‹ˆë‹¤.

> ğŸ’­ $\mathbf{x}\_t$ë¥¼ ë§Œë“¤ ìˆ˜ ìˆëŠ” $q(\mathbf{x}\_{1:T}\|\mathbf{x}\_0)$ëŠ” ë§ì€ë° ê·¸ ì¤‘ Non-Markovianì„ ì‚¬ìš©í•´ì„œ íŠ¹ì • $\mathbf{x}\_t$ë¥¼ ë§Œë“¤ë„ë¡ í•´ ìƒˆë¡œìš´ generative processë¼ ì •ì˜í•œë‹¤ëŠ” ì´ì•¼ê¸°ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.

ğŸ” ìƒˆë¡œìš´ generative process ë˜í•œ DDPMê³¼ ë™ì¼í•œ objective functionì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ğŸ” ë˜í•œ ìƒˆë¡œìš´ generative processë¥¼ ë§Œë“œëŠ” ê°€ì¥ ì¤‘ìš”í•œ ê°œë…ì¸ Non-Markovianì´ Gaussian caseë¥¼ ë„˜ì–´ì„œë„ ì ìš©ë¨ì„ ë³´ì—¬ì£¼ì—ˆìŠµë‹ˆë‹¤.

### 3.1 Non-Markovian Forward Processes

![](../../assets/img/Paper_Reading/DDIM/ddim_6.jpg){: .normal}

ğŸ” ìš°ì„ , inference processë¥¼ Non-Markovianìœ¼ë¡œ ì •ì˜í•´ë³´ê³ ì í•©ë‹ˆë‹¤.

$$
\begin{align}
& q_\sigma(\mathbf{x}_{1:T}|\mathbf{x}_0) := q_\sigma(\mathbf{x}_T|\mathbf{x}_0)\prod^T_{t=2}q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \\

& \qquad \text{where} \\

& \qquad \qquad q_\sigma(\mathbf{x}_T|\mathbf{x}_0) = \mathcal{N}(\sqrt{\alpha_T}\mathbf{x}_0, (1-\alpha_T)\mathrm{I}) \\

& \qquad \qquad q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}\big(\sqrt{\alpha_{t-1}}\mathbf{x}_0 + \sqrt{1-\alpha_{t-1} - \sigma^2_t}\cdot \frac{\mathbf{x}_t - \sqrt{\alpha_t}\mathbf{x}_0}{\sqrt{1-\alpha_t}}, \sigma^2_t\mathrm{I}\big) \quad (t > 1)

\end{align}
$$

ğŸ” ìœ„ì—ì„œ ì •ì˜í•œ inference processê°€ ëª¨ë“  $t$ì—ì„œ ì„±ë¦½í•¨ì„ ê·€ë‚©ë²•ì„ í†µí•´ ì¦ëª…í•´ì•¼ í•©ë‹ˆë‹¤.

1. $q\_\sigma(\mathbf{x}\_T\|\mathbf{x}\_0) = \mathcal{N}(\sqrt{\alpha\_T}\mathbf{x}\_0, (1-\alpha\_T)\mathrm{I})$ìœ¼ë¡œë¶€í„° $q\_\sigma(\mathbf{x}\_t\|\mathbf{x}\_0)$ì™€ $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_0)$ì„ ì •ì˜

   $$
   \begin{align}
       q_\sigma(\mathbf{x}_t|\mathbf{x}_0)\ =&\ \mathcal{N}(\sqrt{\alpha_t}\mathbf{x}_0, (1-\alpha_t)\mathrm{I}) \\
       q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_0)\ =&\ \mathcal{N}(\sqrt{\alpha_{t-1}}\mathbf{x}_0, (1-\alpha_{t-1})\mathrm{I})
   \end{align}
   $$

2. $t$ë¡œë¶€í„° $t-1$ë¥¼ ìœ ë„í•  ìˆ˜ ìˆìœ¼ë©´ ëª¨ë“  $t$ì—ì„œ ì„±ë¦½í•¨ì„ ì¦ëª…

   - Bishop 2.115ë²ˆ ê³µì‹ì„ ë¨¼ì € ì•Œì•„ë´ì•¼ í•©ë‹ˆë‹¤.

     - $p(\mathbf{x})$ê°€ Gaussianì´ê³  $p(\mathbf{y}\|\mathbf{x})$ ë˜í•œ Gaussian distributionì¼ ë•Œ $p(\mathbf{y})$ëŠ” Gaussian

   - Bishop 2.115ë²ˆ ê³µì‹ê³¼ ìœ„ì—ì„œ ì •ì˜í•œ ë‚´ìš©ì„ ì—°ê²° ì‹œì¼œë³´ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.

     $$
     \begin{align}
         &p(\mathbf{x}) &\iff& \qquad q_{\sigma}(\mathbf{x}_t|\mathbf{x}_0)& \\
         &p(\mathbf{y}|\mathbf{x}) &\iff& \qquad q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) \\
         &p(\mathbf{y}) &\iff& \qquad q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_0)& \\
     \end{align}
     $$

   - ìœ„ì—ì„œ $q\_{\sigma}(\mathbf{x}\_t\|\mathbf{x}\_0)$ì™€ $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_t, \mathbf{x}\_0)$ë¥¼ Gaussianìœ¼ë¡œ ì •ì˜í–ˆê¸° ë•Œë¬¸ì— Bishop 2.115ë²ˆ ê³µì‹ì— ë”°ë¼ì„œ $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_0)$ëŠ” Gaussian ì´ë¯€ë¡œ ì•„ë˜ì™€ ê°™ì´ í‘œê¸°ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.

     $$
     \begin{align}
         & q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_0) = \mathcal{N}(\mu_{t-1}, \Sigma_{t-1}) \\ \\

           & \qquad \text{where} \\

           & \qquad \qquad q_\sigma(\mathbf{x}_t|\mathbf{x}_0)\ =\ \mathcal{N}(\sqrt{\alpha_t}\mathbf{x}_0, (1-\alpha_t)\mathrm{I}) \\

           & \qquad \qquad q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0) = \mathcal{N}\big(\sqrt{\alpha_{t-1}}\mathbf{x}_0 + \sqrt{1-\alpha_{t-1} - \sigma^2_t}\cdot \frac{\mathbf{x}_t - \sqrt{\alpha_t}\mathbf{x}_0}{\sqrt{1-\alpha_t}}, \sigma^2_t\mathrm{I}\big) \quad (t > 1)
     \end{align}
     $$

   - $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_t, \mathbf{x}\_0)$ì— $\mathbf{x}\_t$ë¥¼ ëŒ€ì…í•´ì„œ $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_0)$ì˜ í‰ê· ê³¼ ë¶„ì‚°ì„ êµ¬í•©ë‹ˆë‹¤.

     - ìœ„ì—ì„œ ì •ì˜í•œ $q\_\sigma(\mathbf{x}\_t\|\mathbf{x}\_0)\ =\ \mathcal{N}(\sqrt{\alpha\_t}\mathbf{x}\_0, (1-\alpha\_t)\mathrm{I})$ë¡œ ë¶€í„° reparameterization trickì„ í†µí•´ $\mathbf{x}\_t$ë¥¼ êµ¬í•©ë‹ˆë‹¤.

     $$
     \begin{align}
         \mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_0\ +\ \sqrt{1-\alpha_t}\epsilon_t
     \end{align}
     $$

     - $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_t, \mathbf{x}\_0)$ì— $\mathbf{x}\_t$ ëŒ€ì…í•˜ì—¬ í‰ê·  íŒŒíŠ¸ì™€ ë¶„ì‚° íŒŒíŠ¸ë¥¼ ë¶„ë¦¬í•˜ì—¬ ê³„ì‚°í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

     $$
     \begin{align}
         \mu_{t-1}
         &= \sqrt{\alpha_{t-1}}\mathbf{x}_0 + \sqrt{1-\alpha_{t-1} - \sigma^2_t}\cdot \frac{\mathbf{x}_t - \sqrt{\alpha_t}\mathbf{x}_0}{\sqrt{1-\alpha_t}} \\
         &= \sqrt{\alpha_{t-1}}\mathbf{x}_0 + \sqrt{1-\alpha_{t-1} - \sigma^2_t}\cdot \frac{\sqrt{\alpha_t}\mathbf{x}_0 - \sqrt{\alpha_t}\mathbf{x}_0}{\sqrt{1-\alpha_t}} \\
         &= \sqrt{\alpha_{t-1}}\mathbf{x}_0 \\

           \Sigma_{t-1}
         &= \sigma^2_t\mathrm{I}\ +\ (1-\alpha_{t-1} - \sigma^2_t) \cdot \frac{1-\alpha_t}{1-\alpha_t} \mathrm{I} \\
         &= (1-\alpha_{t-1})\mathrm{I}
     \end{align}
     $$

     - ë”°ë¼ì„œ $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_0)\ =\ \mathcal{N}(\sqrt{\alpha\_{t-1}}\mathbf{x}\_0, (1-\alpha\_{t-1})\mathrm{I})$ ì…ë‹ˆë‹¤.

   - $t$ë¡œë¶€í„° $t-1$ë¥¼ ìœ ë„í•˜ì˜€ìœ¼ë¯€ë¡œ ê·€ë‚©ë²•ì— ì˜í•´ì„œ ëª¨ë“  $t$ì—ì„œ ì„±ë¦½í•¨ì„ ì¦ëª…í•  ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.

3. ìœ„ì—ì„œ ì°¾ì€ $q\_{\sigma}(\mathbf{x}\_t\|\mathbf{x}\_0)$, $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_0)$, $q\_\sigma(\mathbf{x}\_{t-1}\|\mathbf{x}\_t, \mathbf{x}\_0)$ì„ Bayes' ruleì„ í†µí•´ $q\_\sigma(\mathbf{x}\_{t}\|\mathbf{x}\_{t-1}, \mathbf{x}\_0)$ì„ êµ¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

   $$
   q_\sigma(\mathbf{x}_{t}|\mathbf{x}_{t-1}, \mathbf{x}_0) = q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_{t}, \mathbf{x}_0) \times \frac{q_{\sigma}(\mathbf{x}_t|\mathbf{x}_0)}{q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_0)}
   $$

4. 3ë²ˆì—ì„œ ì°¾ì€ Bayes' ruleì„ í†µí•´ inference processë¥¼ ì •ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

   $$
   q_\sigma(\mathbf{x}_{1:T}|\mathbf{x}_0) := q_\sigma(\mathbf{x}_T|\mathbf{x}_0)\prod^T_{t=2}q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)
   $$

![](../../assets/img/Paper_Reading/DDIM/ddim_7.jpg){: .normal}

ğŸ” DDPMì˜ diffusion processì™€ ë‹¬ë¦¬ DDIMì˜ forward process(inference process)ëŠ” ë” ì´ìƒ Markovianì´ ì•„ë‹™ë‹ˆë‹¤.

- ë” ì´ìƒ forward processê°€ Markov processê°€ ì•„ë‹ˆë¯€ë¡œ diffusion processë¼ê³  ë¶€ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë”°ë¼ì„œ [Section 3](#3-variational-inference-for-non-markovian-forward-process)ì—ì„œ ì •ë¦¬í•œ ë‚´ìš©ì— ì•½ê°„ì˜ ìˆ˜ì •ì´ í•„ìš”í•©ë‹ˆë‹¤.

  - Inference process : ~~Diffusion process~~ / Forward process
  - Reverse of inference process : ~~Denoising process~~ / Reverse process / <u>Generative process</u>

ğŸ” $\sigma$ì˜ í¬ê¸°ëŠ” forward processê°€ stochastic ì •ë„ë¥¼ í†µì œí•©ë‹ˆë‹¤.

- $\sigma \rightarrow 0$ : ì„ì˜ì˜ $t$ì— ëŒ€í•´ $\mathbf{x}\_{0}$ì™€ $\mathbf{x}\_{t}$ë¥¼ ë°œê²¬í•˜ëŠ” í•œ í•˜ë‚˜ì˜ $\mathbf{x}\_{t-1}$ë¥¼ ì°¾ì„ ìˆ˜ ìˆëŠ” ê·¹ë‹¨ì ì¸ ê²½ìš°ì— ë„ë‹¬í•©ë‹ˆë‹¤.

  > ğŸ’­ DDPMì—ì„œëŠ” ë‹¤ì–‘í•œ $\mathbf{x}\_{t}$ê°€ ë‚˜íƒ€ë‚  ìˆ˜ ìˆëŠ”ë° DDIMì—ì„œëŠ” Non-Markovianì„ í†µí•´ ë‚˜ì˜¬ ìˆ˜ ìˆëŠ” $\mathbf{x}\_{t}$ì˜ ê²½ìš°ì˜ ìˆ˜ë¥¼ ì¡°ì ˆí•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤. ì´ê²ƒì„ ì¡°ì ˆí•˜ëŠ” íŒŒë¼ë¯¸í„°ê°€ $\sigma$ì¸ ê²ƒ ê°™ìŠµë‹ˆë‹¤.
  >
  > ğŸ’­ ê·¸ ì¤‘ì—ì„œ $\sigma$ê°€ 0ì¼ ë•Œ $\mathbf{x}\_{t}$ì˜ ê²½ìš°ì˜ ìˆ˜ë¥¼ í•˜ë‚˜ë¡œ ê³ ì •í•˜ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.
  >
  > ğŸ’­ ì´ì²˜ëŸ¼ $\sigma$ë¥¼ ì¡°ì ˆí•´ì„œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ê°€ëŠ” ê³¼ì •ì„ reverse process ëŒ€ì‹  generative processë¼ ë¶€ë¥´ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤.

### 3.2 Generative Process And Unified Vairational Inference Objective

![](../../assets/img/Paper_Reading/DDIM/ddim_8.jpg){: .normal}

ğŸ” í›ˆë ¨ ê°€ëŠ¥í•œ generative process $p\_{\theta}(\mathbf{x}\_{0:T})$ì—ì„œ ê° $p\_{\theta}^{(t)}(\mathbf{x}\_{t-1}\|\mathbf{x}\_{t})$ëŠ” $q\_{\sigma}(\mathbf{x}\_{t-1}\|\mathbf{x}\_{t}, \mathbf{x}\_{0})$ì„ í™œìš©í•©ë‹ˆë‹¤.

ğŸ” $p\_{\theta}^{(t)}(\mathbf{x}\_{t-1}\|\mathbf{x}\_{t})$ë¥¼ êµ¬í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

1. $\mathbf{x}\_{0} \sim q(\mathbf{x}\_{0})$ì´ê³  $\epsilon\_{t} \sim \mathcal{N}(\mathrm{0}, \mathrm{I})$ ì¼ ë•Œ ì•ì—ì„œ ì •ì˜í•œ ì‹ì„ reparameterization trickì„ í™œìš©í•´ $\mathbf{x}\_t$ë¥¼ êµ¬í•©ë‹ˆë‹¤.

   $$
    \mathbf{x}_t = \sqrt{\alpha_t}\mathbf{x}_0\ +\ \sqrt{1-\alpha_t}\epsilon_t \qquad \because q_{\sigma}(\mathbf{x}_t|\mathbf{x}_0) = \mathcal{N}(\sqrt{\alpha_t}\mathbf{x}_0, (1 -\alpha_t)\mathrm{I})
   $$

2. ëª¨ë¸ $\epsilon\_{\theta}^{t}(\mathbf{x}\_{t})$ì€ $\mathbf{x}\_{t}$ë¡œë¶€í„° $\epsilon\_{t}$ë¥¼ ì˜ˆì¸¡í•˜ê³ ì í•©ë‹ˆë‹¤.

   $$
        L_\gamma(\epsilon_\theta) := \sum^T_{t=1}\gamma_t\mathbb{E}_{\mathbf{x}_0\sim q(\mathbf{x}_0), \epsilon_T \sim \mathcal{N}(\mathrm{0}, \mathrm{I})}\Big[ \lVert \epsilon^{(t)}_\theta (\mathbf{x}_{t})\ -\ \epsilon_t \rVert^2_2 \Big]
   $$

3. ëª¨ë¸ $\epsilon\_{\theta}^{t}(\mathbf{x}\_{t})$ì„ $\mathbf{x}\_t = \sqrt{\alpha\_t}\mathbf{x}\_0\ +\ \sqrt{1-\alpha\_t}\epsilon\_t$ì—ì„œ $\epsilon\_t$ ëŒ€ì‹  ëŒ€ì…í•˜ê³  í•´ë‹¹ ì‹ì„ $\mathbf{x}\_0$ìœ¼ë¡œ ì •ë¦¬í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

   $$
       \begin{align}
       f_{\theta}^{(t)}(\mathbf{x}_{t})
       &=\ \hat{\mathbf{x}}_0 \\
       &=\ (\mathbf{x}_t - \sqrt{1-\alpha_{t}}\cdot \epsilon_{\theta}^{t}(\mathbf{x}_{t})) / \sqrt{\alpha_{t}}
       \end{align}
   $$

4. ë”°ë¼ì„œ ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

   $$
   \begin{align}
   q_{\sigma}(\mathbf{x}_{t-1}|\mathbf{x}_{t}, \hat{\mathbf{x}}_{0})
   &= q_{\sigma}(\mathbf{x}_{t-1}|\mathbf{x}_{t}, f_\theta^{(t)}(\mathbf{x}_t)) \\
   &= \mathcal{N}\big(\sqrt{\alpha_{t-1}}\mathbf{x}_0 + \sqrt{1-\alpha_{t-1} - \sigma^2_t}\cdot \frac{\mathbf{x}_t - \sqrt{\alpha_t}f_{\theta}^{(t)}(\mathbf{x}_{t})}{\sqrt{1-\alpha_t}}, \sigma^2_t\mathrm{I}\big)
   \end{align}
   $$

5. ì´ì œ generative processë¥¼ ì •ì˜í•˜ê² ìŠµë‹ˆë‹¤.

   - $p\_{\theta}(\mathbf{x}\_{T}) = \mathcal{N}(\mathrm{0}, \mathrm{I})$ë¡œ ê³ ì •
   - Generative processê°€ ëª¨ë“  ê³³ì—ì„œ ì‘ë™í•˜ë„ë¡ í•˜ê¸° ìœ„í•´ $t=1$ì¼ ë•Œ Gaussian noiseë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
     - ìœ„ì—ì„œ inference processë¥¼ ì •ì˜í•  ë•Œ $t$ê°€ 1ë³´ë‹¤ í´ ë•Œ $q\_{\sigma}(\mathbf{x}\_{t-1}\|\mathbf{x}\_{t}, \mathbf{x}\_{0})$ì„ ì •ì˜í–ˆê¸° ë•Œë¬¸ì— $t=1$ì¼ ë•Œ ë”°ë¡œ ì •ì˜ê°€ í•„ìš”í–ˆìŒ
     - $p\_{\theta}^{(1)}(\mathbf{x}\_{0}\|\mathbf{x}\_{1}) = \mathcal{N}(f\_\theta^{(1)}(\mathbf{x}\_1),\ \sigma\_1^2\mathrm{I})$
   - ë§ˆì§€ë§‰ìœ¼ë¡œ generative processë¥¼ ì •ì˜í•˜ë©´ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

     $$
         p_{\theta}^{(t)}(\mathbf{x}_{t-1}|\mathbf{x}_{t})=
         \begin{cases}
         \mathcal{N}(f_\theta^{(1)}(\mathbf{x}_1),\ \sigma_1^2\mathrm{I}), & \text{if } t = 1 \\
         q_{\sigma}(\mathbf{x}_{t-1}|\mathbf{x}_{t}, f_\theta^{(t)}(\mathbf{x}_t)), & \text{otherwise}
         \end{cases}
     $$

![](../../assets/img/Paper_Reading/DDIM/ddim_9.jpg){: .normal}

ğŸ” í•´ë‹¹ ë…¼ë¬¸ì—ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ objective functionì„ ì •ì˜í–ˆìŠµë‹ˆë‹¤.

$$
\begin{align}
J_{\sigma} :=& \ \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}[\log q_\sigma(\mathbf{x}_{1:T}|\mathbf{x}_{0}) - \log p_{\theta}(\mathbf{x}_{0:T})]  & \qquad \\
=&\ \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\Bigg[\bigg(\log q_\sigma(\mathbf{x}_T|\mathbf{x}_0)\prod^T_{t=2}q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0) \bigg) - \bigg(\log p_\theta(\mathbf{x}_T)\prod^T_{t=1}p_\theta^{(t)}(\mathbf{x}_{t-1}|\mathbf{x}_t) \bigg)\Bigg]  & \qquad \\
=&
\ \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\Bigg[ \log q_\sigma(\mathbf{x}_T|\mathbf{x}_0) + \sum^T_{t=2}\log q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_{t}, \mathbf{x
}_{0}) - \sum^T_{t=1} \log p_\theta^{(t)} (\mathbf{x}_{t-1}|\mathbf{x}_t) - \log p_\theta(\mathbf{x}_T) \Bigg]  & \qquad \\
=&
\ \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\Bigg[ \log q_\sigma(\mathbf{x}_T|\mathbf{x}_0) + \sum^T_{t=2}\log \frac{q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)}{p^{(t)}_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} - \log p^{(1)}_\theta(\mathbf{x}_0|\mathbf{x}_1) - \log p_\theta(\mathbf{x}_T) \Bigg]  & \qquad \\
\equiv&
\ \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\Bigg[ \sum^T_{t=2}\log \frac{q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)}{p^{(t)}_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)} - \log p^{(1)}_\theta(\mathbf{x}_0|\mathbf{x}_1)\Bigg] & \qquad \because \text{í•™ìŠµì— í•„ìš”í•˜ì§€ ì•Šì€ ë¶€ë¶„ ì‚­ì œ}\\
=&
\ \sum^T_{t=2}\mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\Bigg[\log \frac{q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t, \mathbf{x}_0)}{p^{(t)}_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)}\Bigg] - \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\big[\log p^{(1)}_\theta(\mathbf{x}_0|\mathbf{x}_1)\big] \\
=&
\ \sum^T_{t=2}D_{KL}(q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)\ ||\ p^{(t)}_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)) - \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\big[\log p^{(1)}_\theta(\mathbf{x}_0|\mathbf{x}_1)\big]
\end{align}
$$

- ìœ„ì˜ objective functionì—ì„œ $t > 1$ì¼ ë•Œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

  $$
  \begin{align}
  D_{KL}(q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)\ ||\ p^{(t)}_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t))
  &= D_{KL}(q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)\ ||\ q_{\sigma}(\mathbf{x}_{t-1}|\mathbf{x}_{t}, f_\theta^{(t)}(\mathbf{x}_t))) & \qquad \\
  &= \mathbb{E}_{\mathbf{x}_{0},\ \mathbf{x}_{t}\ \sim\ q_{\sigma}(\mathbf{x}_{0},\ \mathbf{x}_{t})} \Bigg[\frac{1}{2\sigma^2_t}\lVert \mathbf{x}_0 - f^{(t)}_\theta(\mathbf{x}_t)\rVert^2_2\Bigg] & \qquad \because \text{ë¶„ì‚°ì´ ê°™ì€ ë‘ Gaussian distribution} \\
  &= \mathbb{E}_{\mathbf{x}_{0}\ \sim\ q_{\sigma}(\mathbf{x}_{0}),\ \epsilon\ \sim \mathcal{N}(\mathrm{0},\ \mathrm{I}),\ \mathbf{x}_t=\sqrt{\alpha_t}\mathbf{x}_0 + \sqrt{1-\alpha_t}\epsilon_t} \Bigg[\frac{1}{2\sigma^2_t}\bigg\lVert \frac{\mathbf{x}_t - \sqrt{1-\alpha_t}\epsilon_t}{\sqrt{\alpha_t}} - \frac{\mathbf{x}_t - \sqrt{1-\alpha_t}\epsilon^{(t)}_\theta(\mathbf{x}_t)}{\sqrt{\alpha_t}} \bigg\rVert^2_2  \Bigg] \\
  &= \mathbb{E}_{\mathbf{x}_{0}\ \sim\ q_{\sigma}(\mathbf{x}_{0}),\ \epsilon\ \sim \mathcal{N}(\mathrm{0},\ \mathrm{I}),\ \mathbf{x}_t=\sqrt{\alpha_t}\mathbf{x}_0 + \sqrt{1-\alpha_t}\epsilon_t}\Bigg[\frac{1-\alpha_t}{2\sigma^2_t\alpha_t}\bigg\lVert  \epsilon_t\ -\ \epsilon^{(t)}_\theta(\mathbf{x}_t)\bigg\rVert^2_2  \Bigg]
  \end{align}
  $$

- ì´ì œëŠ” objective functionì—ì„œ $t=1$ì¼ ë•Œë¥¼ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤.

  $$
  \begin{align}
  \mathbb{E}_{\mathbf{x}_{0},\ \mathbf{x}_{1}\ \sim\ q_{\sigma}(\mathbf{x}_{0},\ \mathbf{x}_{1})}\big[-\log p^{(1)}_\theta(\mathbf{x}_0|\mathbf{x}_1)\big]
  &\equiv \mathbb{E}_{\mathbf{x}_{0},\ \mathbf{x}_{1}\ \sim\ q_{\sigma}(\mathbf{x}_{0},\ \mathbf{x}_{1})}\Bigg[\frac{1}{2\sigma^2_1}\bigg\lVert\mathbf{x}_0 - f^{(1)}_\theta(\mathbf{x}_1) \bigg\rVert^2_2\Bigg] \\
  &= \mathbb{E}_{\mathbf{x}_{0}\ \sim\ q_{\sigma}(\mathbf{x}_{0}),\ \epsilon\ \sim \mathcal{N}(\mathrm{0},\ \mathrm{I}),\ \mathbf{x}_1=\sqrt{\alpha_1}\mathbf{x}_0 + \sqrt{1-\alpha_1}\epsilon_1} \Bigg[\frac{1}{2\sigma^2_1}\bigg\lVert \frac{\mathbf{x}_1 - \sqrt{1-\alpha_1}\epsilon_1}{\sqrt{\alpha_1}} - \frac{\mathbf{x}_1 - \sqrt{1-\alpha_1}\epsilon^{(1)}_\theta(\mathbf{x}_1)}{\sqrt{\alpha_1}} \bigg\rVert^2_2  \Bigg] \\
  &= \mathbb{E}_{\mathbf{x}_{0}\ \sim\ q_{\sigma}(\mathbf{x}_{0}),\ \epsilon\ \sim \mathcal{N}(\mathrm{0},\ \mathrm{I}),\ \mathbf{x}_1=\sqrt{\alpha_1}\mathbf{x}_0 + \sqrt{1-\alpha_1}\epsilon_1} \Bigg[\frac{1-\alpha_1}{2\sigma^2_1\alpha_1}\bigg\lVert  \epsilon_1\ -\ \epsilon^{(1)}_\theta(\mathbf{x}_1)\bigg\rVert^2_2  \Bigg]
  \end{align}
  $$

- ë”°ë¼ì„œ ìµœì¢… objective functionì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

  $$
  \begin{align}
  J_\sigma &\equiv \sum^T_{t=2}D_{KL}(q_\sigma(\mathbf{x}_{t-1}|\mathbf{x}_t,\mathbf{x}_0)\ ||\ p^{(t)}_\theta(\mathbf{x}_{t-1}|\mathbf{x}_t)) - \mathbb{E}_{\mathbf{x}_{0:T}\sim q_{\sigma}(\mathbf{x}_{0:T})}\big[\log p^{(1)}_\theta(\mathbf{x}_0|\mathbf{x}_1)\big] \\
  &= \sum^T_{t=2}\mathbb{E}_{\mathbf{x}_{0}\ \sim\ q_{\sigma}(\mathbf{x}_{0}),\ \epsilon\ \sim \mathcal{N}(\mathrm{0},\ \mathrm{I}),\ \mathbf{x}_t=\sqrt{\alpha_t}\mathbf{x}_0 + \sqrt{1-\alpha_t}\epsilon_t}\Bigg[\frac{1-\alpha_t}{2\sigma^2_t\alpha_t}\bigg\lVert  \epsilon_t\ -\ \epsilon^{(t)}_\theta(\mathbf{x}_t)\bigg\rVert^2_2  \Bigg] + \mathbb{E}_{\mathbf{x}_{0}\ \sim\ q_{\sigma}(\mathbf{x}_{0}),\ \epsilon\ \sim \mathcal{N}(\mathrm{0},\ \mathrm{I}),\ \mathbf{x}_1=\sqrt{\alpha_1}\mathbf{x}_0 + \sqrt{1-\alpha_1}\epsilon_1} \Bigg[\frac{1-\alpha_1}{2\sigma^2_1\alpha_1}\bigg\lVert  \epsilon_1\ -\ \epsilon^{(1)}_\theta(\mathbf{x}_1)\bigg\rVert^2_2  \Bigg] \\
  &= \sum^T_{t=1}\mathbb{E}_{\mathbf{x}_{0}\ \sim\ q_{\sigma}(\mathbf{x}_{0}),\ \epsilon\ \sim \mathcal{N}(\mathrm{0},\ \mathrm{I}),\ \mathbf{x}_t=\sqrt{\alpha_t}\mathbf{x}_0 + \sqrt{1-\alpha_t}\epsilon_t}\Bigg[\frac{1-\alpha_t}{2\sigma^2_t\alpha_t}\bigg\lVert  \epsilon_t\ -\ \epsilon^{(t)}_\theta(\mathbf{x}_t)\bigg\rVert^2_2  \Bigg] \\
  &= \sum^T_{t=1}\frac{1-\alpha_t}{2\sigma^2_t\alpha_t}\mathbb{E}\bigg[\big\lVert  \epsilon_t\ -\ \epsilon^{(t)}_\theta(\mathbf{x}_t)\big\rVert^2_2  \bigg] \\
  &= L_\gamma \qquad \text{when }\gamma_t = \frac{1-\alpha_t}{2\sigma^2_t\alpha_t}
  \end{align}
  $$

- ìµœì¢… objective functionì„ ìƒëµ ì—†ì´ ë‚˜íƒ€ë‚¸ë‹¤ë©´ ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

  $$J_\sigma(\epsilon_\theta) = L_\gamma(\epsilon_\theta) + C$$

## 4. Sampling From Generalized Generative Processes

ì§„í–‰ ì¤‘...
