---
layout: post
title: "[Generative Model] Pix2Pix : Image-to-Image Translation with Conditional Adversarial Networks"
author: kjy
date: 2023-12-26 16:28:00 +09:00
categories: [Deep Learning, Paper Reading]
tags: [Deep Learning, Paper Reading, Computer Vision, Generative Model]
comments: true
toc: true
math: true
---

해당 포스트에서는 [Pix2Pix : Image-to-Image Translation with Conditional Adversarial Networks](https://arxiv.org/abs/1611.07004) 논문을 함께 읽어가도록 하겠습니다. 문장마다 해석을 하기 보다는 각 문단에서 중요한 부분을 요약하는 식으로 진행하겠습니다.

## Abstract

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_1.jpg){: width="400" .left}

> 🔎 해당 논문은 image-to-image translation problems의 general-purpose solution에 대한 conditional adversarial networks을 조사합니다.

> 🔎 Conditional adversarial networks는 image-to-image mapping을 하나의 loss function을 통해 학습됩니다.

> 🔎 하나의 loss function으로 mapping을 학습하는 것이 이전 연구와는 다른 점입니다.

> 🔎 특히 해당 networks는 synthesizing photos from label maps, reconstructing objects from edge maps, colorizing images에 효과적인 접근법입니다.

<br><br>

## 1. Introduction

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_2.jpg){: width="400" .left}

🔎 Image processing, computer graphics, computer vision에서의 많은 문제는 image-to-image에 해당할 것입니다.

🔎 이전 연구에서는 pixel-to-pixel이라는 공통적인 부분이 있음에도 별개의 문제로 다뤘습니다.

🔎 그래서 해당 연구에서는 automatic image-to-image translation을 정의하고자 합니다.

🔎 해당 연구의 간단한 결과는 [Figure 1](#figure-1)에서 확인할 수 있습니다.

<br>

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_3.jpg){: width="400" .left}

🔎 CNN의 learning process는 자동이지만 효과적인 loss function을 만들기 위해서는 수동적인 노력이 필요합니다.

🔎 Loss function으로 naive한 접근법인 Euclidean distance로 사용할 경우 blurry한 결과를 얻게 될 것입니다.

🔎 왜냐하면 Euclidean distance는 평균을 최소화 하기 때문에 전체적으로 그럴듯한 결과를 만들기 때문입니다.

<br>

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_4.jpg){: width="400" .left}

🔎 해당 task에 가장 바람직한 loss function은 GAN의 loss function이라고 할 수 있습니다.

🔎 GAN의 loss function은 data의 분포를 학습하기 때문에 blurry한 결과를 피할 수 있습니다.

🔎 또한 GAN의 loss function은 전통적으로 매우 다른 종류의 loss function을 필요로 하는 다양한 작업에 적용할 수 있습니다.

<br>

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_5.jpg){: width="400" .left}

🔎 해당 논문에서는 conditional GANs을 연구합니다.

🔎 왜냐하면 조건화된 이미지를 입력으로 주고 그에 대응하는 결과 이미지를 생성하는 것이 image-to-image translation에 적합하기 때문입니다.

<br>

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_6.jpg){: width="400" .left}

🔎 해당 논문의 contribution을 두 개로 정리할 수 있습니다.

🔎 첫 번째, 다양한 문제에서 cGANs가 합리적인 결과를 도출할 수 있음을 입증합니다.

🔎 두 번째, 좋은 결과를 얻기 위해 간단한 framework를 제시하고 몇 가지 중요한 architecture 선택의 효과를 분석합니다.

<br><br>

## 2. Related work

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_7.jpg){: width="400" .left}

🔎 Image-to-image translation problem은 per pixel classification 또는 regression으로 공식화됩니다.

🔎 이러한 방식은 unstructured라고 output space를 만들어냅니다.

🔎 그러나 cGANs는 structured loss를 학습하기 때문에 output과 target 사이의 차이에 불이익을 주며 output space를 구조화 할 수 있습니다.

<br><br><br><br>

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_8.jpg){: width="400" .left}

🔎 이전 연구들에서는 unconditional GANs과 L2 regression과 같은 다른 term을 추가해 image-to-image task를 수행하여 특정 분야에서 좋은 결과를 얻었습니다.

🔎 그러나 해당 논문의 framework는 conditional GANs 외에 다른 term이 추가되지 않습니다.

🔎 그렇기 때문에 다른 framework보다 간단하다고 할 수 있습니다.

<br><br><br><br>

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_9.jpg){: width="400" .left}

🔎 이전 연구와 다르게 몇몇 다른 acrhitecture를 generator와 discriminator에서 사용했습니다.

🔎 Generator에서는 `U-Net`구조의 architecture를 선택했습니다.

🔎 Discriminator에서는 `PatchGAN`의 clssifier를 사용했습니다.

🔎 PatchGAN 구조가 더 다양한 범위의 문제를 해결하는데 효과적임을 해당 논문에서 보여줍니다.

💭 Local style statistics를 확인하는 것이 왜 다양한 범위의 문제를 해결하는데 더 효과적일까?

💭 Patch 크기에 따른 결과?

<br><br>

## 3. Method

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_10.jpg){: width="400" .left}

🔎 GANs과 cGANs의 차이는 training images $x$가 generator의 입력으로 random noise vector $z$와 함께 들어가는지 여부입니다.

🔎 GANs : $G : z \rightarrow y$

🔎 cGANs : $G : \\{x, z\\} \rightarrow y$

<br><br>

### 3.1 Objective

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_11.jpg){: width="400" .left}

🔎 cGANs의 objective function은 아래와 같이 나타낼 수 있습니다.

$$\begin{align} \mathcal{L}_{cGAN}(G, D) = &\mathbb{E}_{x,y}[\log{D(x,y)}] + \\ &\mathbb{E}_{x,z}[\log{1-D(x,G(x,z))}] \end{align}$$

🔎 여기서 $G$는 objective function을 최대화하려는 $D$에 대해서 objective function을 최소화하려합니다. 따라서 아래와 같이 $G$의 objective function을 나타낼 수 있습니다.

$$G^{*} = \text{arg}\ \text{min}_G\ \text{max}_D\ \mathcal{L}_{cGAN}(G, D)$$

🔎 Conditioning discriminator의 중요성을 확인하기위해 unconditional GANs도 비교합니다.

$$\begin{align} \mathcal{L}_{GAN}(G, D) = &\mathbb{E}_{y}[\log{D(y)}] + \\ &\mathbb{E}_{x, z}[\log{1-D(x,G(z))}] \end{align}$$

🔎 이전 연구들처럼 L2 regression과 같은 term을 사용하는 것이 더 효과적인지 해당 논문에서 확인합니다. 그 중에서 blurring이 덜 한 L1 distance를 사용했습니다.

$$\mathcal{L}_{L1}(G) = \mathbb{E}_{x,y,z}[||y - G(x,z)||_1]$$

🔎 최종 objective function은 아래와 같습니다.

$$G^{*} = \text{arg}\ \underset{G}{\text{min}}\ \underset{D}{\text{max}}\ \mathcal{L}_{cGAN}(G, D) + \lambda\mathcal{L}_{L1}(G)$$

<br>

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_12.jpg){: width="400" .left}

🔎 Random noise vector $z$가 없을 때 여전히 $x \rightarrow y$를 학습하지만 deterministic outputs을 만들어냅니다.

🔎 Deterministic outputs이란, 동일한 x가 주어졌을 때 동일한 output이 나온다는 뜻입니다. 이것을 확률분포 관점에서 본다면 delta function 외에 어떠한 분포와도 매칭이되지 않는 것을 말합니다.

🔎 초기 실험에서는 random noise vector $z$의 역할이 보이지 않았습니다.

🔎 그러나 해당 논문의 최종 모델에서는 random noise vector $z$가 dropout 형태로 generator에게 영향을 주고 있는 것을 알 수 있었습니다.

🔎 이런 random noise vector $z$가 작은 확률적 변화를 만들어낸 것을 알 수 있었습니다.

🔎 많은 확률적 변화를 만들어 내도록 cGANs를 설계하는 것이 추후 연구가 될 수 있습니다.

### 3.2 Network architecture

#### 3.2.1 Generator with skips

#### 3.2.2 Markovian discriminator (PatchGAN)

### 3.3 Optimization and inference

## 4. Experiments

### 4.1 Evaluation metrics

### 4.2 Analysis of the objective function

### 4.3 Analysis of the generator architecture

### 4.4 From PixelGANs to Patch GANs to ImageGANs

### 4.5 Perceptual validation

### 4.6 Semantic segmentation

### 4.7 Community-driven Research

## 5. Conclusion

## Figure

### Figure 1

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f1.jpg){: width="400" .left}

🔎 같은 architecture, objective와 서로 다른 training data를 사용해 학습한 결과를 보여줍니다.

![](../../assets/img/Paper_Reading/Pix2Pix/pix2pix_f2.jpg){: width="400" .left}

🔎 GANs과 달리 cGANs에서는 generator와 discriminator 모두에 input image $x$가 들어가는 것을 그림으로 보여줍니다.

## Table
