---
layout: post
title: "[Evaluation] BLEU"
author: kjy
date: 2023-08-28 17:40:00 +09:00
categories: [Evaluation, NLP]
tags: [Evaluation, NLP]
comments: true
toc: true
math: true
---

해당 포스트에서는 machine translation을 평가하는데 사용되는 BLEU(Bilingual Evaluation Understudy Score)에 대해서 알아보겠습니다.

---

## 1. BLEU의 특징

BLEU의 특징은 다음과 같습니다.

> - 언어에 구애받지 않고 사용할 수 있다.
> - 계산 속도가 빠르다.
> - BLEU의 값이 클수록 성능이 더 좋다.

---

## 2. BLEU의 요소

다음은 BLEU를 측정하는데 있어서 고려되는 요소들에 무엇이 있는지 알아보겠습니다.

### 2.1 Precision

BLEU에서 precision을 어떻게 구하는지 알아보기에 앞서서 precision의 식을 다시 한 번 살펴보고 가겠습니다.

$$ Precision = \frac{TP}{TP + FP}$$

Precision 식을 말로 설명하게 되면 **모델이 True라고 예측한 것 중에 실제 True인 것의 비율**이라고 할 수 있습니다. 이를 BLEU에서는 **모델이 예측한 단어 중에 실제 정답 문장에 있는 단어의 수의 비율**로 계산을 합니다. 그러나 단어 하나만을 기준으로 계산을 하게 되면 문장에 존재하는 단어의 순서는 고려가 되지 않게 됩니다. 그렇기 때문에 여기서 n-gram이라는 방법을 사용하게 됩니다.

정리를 해보자면 BLEU에서는 n-gram을 통해 단어의 순서쌍들이 얼마나 겹치는지(precision)를 측정하게 됩니다.

$$ Precision = \frac{\text{예측한 문장에서 정답 문장과 일치하는 n-gram의 수}}{\text{예측된 문장의 n-gram의 수}} $$

### 2.2 Clipping

위의 precision을 통해 평가를 할 경우 하나의 단어 또는 단어 쌍들이 반복되는 예측된 문장에 대해서 높은 점수를 부여할 수 있기 때문에 이를 방지할 수 있는 장치가 필요합니다.

이러한 장치를 clipping이라 하며 같은 단어가 연속적으로 나올 때 과적합 되는 것을 보정하게 됩니다. 자세히는 apple이라는 단어가 정답 문장과 일치하고 apple이라는 단어가 예측 문장에서는 3개가 등장하고 정답 문장에서는 2개가 등장한다고 하면 이때 보정된 precision의 분자의 값은 2가 됩니다. 이를 식으로 나타내면 다음과 같습니다.

$$Precision_{clip} = \frac{\min(\text{예측한 문장에서 정답 문장과 일치하는 n-gram의 수}, \text{정답 문장에서 예측한 문장과 일치하는 n-gram의 수})}{\text{예측된 문장의 n-gram의 수}}$$

Precision으로 계산한 것과 이후에 clipping을 적용했을 때의 차이를 예시를 통해 알아보겠습니다.

🔎 Example

> `True` : <U>My</U> favoriate <U>movie</U> is abcdef\
> `Pred` : <U>My</U> <U>movie</U> <U>movie</U> <U>movie</U> is abcdef\
> $$1-gram\ precision = \frac{\text{My} + \text{movie}}{\text{Total}} = \frac{1 + 3}{6}$$ \
> $$1-gram\ precision_{clip} = \frac{\text{My} + \text{movie}}{\text{Total}} = \frac{1 + 1}{6}$$

### 2.3 Brevity Penalty

위와 같이 보정이 들어가더라도 남아 있는 문제가 있습니다. 바로 예측된 문장의 길이가 precision 분모에 그대로 들어감으로써 예측된 문장의 길이에 영향을 받을 수 있다는 점입니다. 따라서 예측된 문장의 길이가 정답 문장의 길이보다 짧은 경우 BLEU 점수에 패널티를 주도록 하는 것이 Brevity penalty 입니다.

Brevity Penalty는 위에서 구한 precision 값에 곱하게 되는데 다음과 같이 구할 수 있습니다.

$$\min(1, \frac{\text{예측된 문장의 길이}}{\text{정답 문장의 길이}})$$

---

## 3. BLEU Score

위에서 언급했던 것들을 종합해 보면 다음과 같은 공식으로 BLEU Score를 구할 수 있습니다.

$$BLEU = \min(1, \frac{\text{예측된 문장의 길이}}{\text{정답 문장의 길이}})(\prod^4_{i=1}precision_i)^{\frac{1}{4}}$$

---

## ※ Reference

[https://wikidocs.net/31695](https://wikidocs.net/31695)\
[https://donghwa-kim.github.io/BLEU.html](https://donghwa-kim.github.io/BLEU.html)
